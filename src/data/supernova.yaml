- bibtex: "@inproceedings{wuB2BridgingCode2020,\n  title = {B2: {{Bridging Code}}\
    \ and {{Interactive Visualization}} in {{Computational Notebooks}}},\n  shorttitle\
    \ = {B2},\n  booktitle = {Proceedings of the 33rd {{Annual ACM Symposium}} on\
    \ {{User Interface Software}} and {{Technology}}},\n  author = {Wu, Yifan and\
    \ Hellerstein, Joseph M. and Satyanarayan, Arvind},\n  year = {2020},\n  doi =\
    \ {10.1145/3379337.3415851},\n  url = {https://dl.acm.org/doi/10.1145/3379337.3415851},\n\
    \  urldate = {2021-09-15},\n  langid = {english}\n}\n"
  communication: ''
  description: 'Data scientists have embraced computational notebooks to author analysis
    code and accompanying visualizations within a single document. Currently, although
    these media may be interleaved, they remain siloed: interactive visualizations
    must be manually specified as they are divorced from the analysis provenance expressed
    via dataframes, while code cells have no access to users'' interactions with visualizations,
    and hence no way to operate on the results of interaction. To bridge this divide,
    we present B2, a set of techniques grounded in treating data queries as a shared
    representation between the code and interactive visualizations. B2 instruments
    data frames to track the queries expressed in code and synthesize corresponding
    visualizations. These visualizations are displayed in a dashboard to facilitate
    interactive analysis. When an interaction occurs, B2 reifies it as a data query
    and generates a history log in a new code cell. Subsequent cells can use this
    log to further analyze interaction results and, when marked as reactive, to ensure
    that code is automatically recomputed when new interaction occurs. In an evaluative
    study with data scientists, we find that B2 promotes a tighter feedback loop between
    coding and interacting with visualizations. All participants frequently moved
    from code to visualization and vice-versa, which facilitated their exploratory
    data analysis in the notebook.'
  githubURL: https://github.com/yifanwu/b2
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: b2
  otherURLs: []
  paperURL: https://dl.acm.org/doi/abs/10.1145/3379337.3415851
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{bauerleSymphonyComposingInteractive2022,\n  title = {Symphony:\
    \ {{Composing Interactive Interfaces}} for {{Machine Learning}}},\n  shorttitle\
    \ = {Symphony},\n  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing\
    \ Systems}}},\n  author = {B{\\\"a}uerle, Alex and Cabrera, {\\'A}ngel Alexander\
    \ and Hohman, Fred and Maher, Megan and Koski, David and Suau, Xavier and Barik,\
    \ Titus and Moritz, Dominik},\n  year = {2022},\n  doi = {10.1145/3491102.3502102},\n\
    \  url = {https://dl.acm.org/doi/10.1145/3491102.3502102},\n  urldate = {2022-08-24},\n\
    \  langid = {english}\n}\n"
  communication: ''
  description: Interfaces for machine learning (ML), information and visualizations
    about models or data, can help practitioners build robust and responsible ML systems.
    Despite their benefits, recent studies of ML teams and our interviews with practitioners
    (n=9) showed that ML interfaces have limited adoption in practice. While existing
    ML interfaces are effective for specific tasks, they are not designed to be reused,
    explored, and shared by multiple stakeholders in cross-functional teams. To enable
    analysis and communication between different ML practitioners, we designed and
    implemented Symphony, a framework for composing interactive ML interfaces with
    task-specific, data-driven components that can be used across platforms such as
    computational notebooks and web dashboards. We developed Symphony through participatory
    design sessions with 10 teams (n=31), and discuss our findings from deploying
    Symphony to 3 production ML projects at Apple. Symphony helped ML practitioners
    discover previously unknown issues like data duplicates and blind spots in models
    while enabling them to share insights with other stakeholders.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: symphony
  otherURLs: []
  paperURL: https://dl.acm.org/doi/abs/10.1145/3491102.3502102
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{leeLuxAlwaysonVisualization2021,\n  title = {Lux: Always-on Visualization\
    \ Recommendations for Exploratory Dataframe Workflows},\n  shorttitle = {Lux},\n\
    \  author = {Lee, Doris Jung-Lin and Tang, Dixin and Agarwal, Kunal and Boonmark,\
    \ Thyne and Chen, Caitlyn and Kang, Jake and Mukhopadhyay, Ujjaini and Song, Jerry\
    \ and Yong, Micah and Hearst, Marti A. and Parameswaran, Aditya G.},\n  year =\
    \ {2021},\n  journal = {Proceedings of the VLDB Endowment},\n  volume = {15},\n\
    \  doi = {10.14778/3494124.3494151},\n  url = {https://dl.acm.org/doi/10.14778/3494124.3494151},\n\
    \  urldate = {2023-04-13},\n  langid = {english}\n}\n"
  communication: ''
  description: Exploratory data science largely happens in computational notebooks
    with dataframe APIs, such as pandas, that support flexible means to transform,
    clean, and analyze data. Yet, visually exploring data in dataframes remains tedious,
    requiring substantial programming effort for visualization and mental effort to
    determine what analysis to perform next. We propose Lux, an always-on framework
    for accelerating visual insight discovery in dataframe workflows. When users print
    a dataframe in their notebooks, Lux recommends visualizations to provide a quick
    overview of the patterns and trends and suggests promising analysis directions.
    Lux features a high level language for generating visualizations on demand to
    encourage rapid visual experimentation with data. We demonstrate that through
    the use of a careful design and three system optimizations, Lux adds no more than
    two seconds of overhead on top of pandas for over 98% of datasets in the UCI repository.
    We evaluate Lux in terms of usability via a controlled first-use study and interviews
    with early adopters, finding that Lux helps fulfill the needs of data scientists
    for visualization support within their dataframe workflows. Lux has already been
    embraced by data science practitioners, with over 3.1k stars on Github.
  githubURL: https://github.com/lux-org/lux
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: lux
  otherURLs: []
  paperURL: https://arxiv.org/abs/2105.00121
  releaseYear: 2021
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{scully-allisonDesigningInteractiveNotebookEmbedded2022,\n  title\
    \ = {Designing an {{Interactive}}, {{Notebook-Embedded}}, {{Tree Visualization}}\
    \ to {{Support Exploratory Performance Analysis}}},\n  author = {{Scully-Allison},\
    \ Connor and Lumsden, Ian and Williams, Katy and Bartels, Jesse and Taufer, Michela\
    \ and Brink, Stephanie and Bhatele, Abhinav and Pearce, Olga and Isaacs, Katherine\
    \ E.},\n  year = {2022},\n  url = {http://arxiv.org/abs/2205.04557},\n  urldate\
    \ = {2023-04-03},\n  archiveprefix = {arxiv},\n  journal = {2205.04557}\n}\n"
  communication: ''
  description: Interactive visualization via direct manipulation has inherent design
    trade-offs in flexibility, discoverability, and ease-of-use. Scripting languages
    can support a vast range of user queries and tasks, but may be more cumbersome
    for free-form exploration. Embedding interactive visualization in a scripting
    environment, such as a computational notebook, provides an opportunity for leveraging
    the strengths of both direct manipulation and scripting. We conduct a design study
    investigating this opportunity in the context of calling context trees as used
    for performance analysis of parallel software. Our collaborators make new performance
    analysis functionality available to users via Jupyter notebook examples, making
    the project setting conducive to such an investigation. Through a series of semi-structured
    interviews and regular meetings with project stakeholders, we produce a formal
    task analysis grounded in the expectation that tasks may be supported by scripting,
    interactive visualization, or both paradigms. We then design an interactive bivariate
    calling context tree visualization for embedding in Jupyter notebooks with features
    to pass data and state between the scripting and visualization contexts. We evaluated
    our embedded design with seven high performance computing experts. The experts
    were able to complete tasks and provided further feedback on the visualization
    and the notebook-embedded interactive visualization paradigm. We reflect upon
    the project and discuss factors in both the process and the design of the embedded
    visualization.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: calling-context-tree
  otherURLs: []
  paperURL: https://arxiv.org/abs/2205.04557
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{liEDAssistantSupportingExploratory2023,\n  title = {{{EDAssistant}}:\
    \ {{Supporting Exploratory Data Analysis}} in {{Computational Notebooks}} with\
    \ {{In Situ Code Search}} and {{Recommendation}}},\n  shorttitle = {{{EDAssistant}}},\n\
    \  author = {Li, Xingjun and Zhang, Yizhi and Leung, Justin and Sun, Chengnian\
    \ and Zhao, Jian},\n  year = {2023},\n  journal = {ACM Transactions on Interactive\
    \ Intelligent Systems},\n  volume = {13},\n  doi = {10.1145/3545995},\n  url =\
    \ {https://dl.acm.org/doi/10.1145/3545995},\n  urldate = {2023-04-03},\n  langid\
    \ = {english}\n}\n"
  communication: ''
  description: "Using computational notebooks (e.g., Jupyter Notebook), data scientists\
    \ rationalize their exploratory data analysis (EDA) based on their prior experience\
    \ and external knowledge, such as online examples. For novices or data scientists\
    \ who lack specific knowledge about the dataset or problem to investigate, effectively\
    \ obtaining and understanding the external information is critical to carrying\
    \ out EDA. This article presents EDAssistant, a JupyterLab extension that supports\
    \ EDA with in situ search of example notebooks and recommendation of useful APIs,\
    \ powered by novel interactive visualization of search results. The code search\
    \ and recommendation are enabled by advanced machine learning models, trained\
    \ on a large corpus of EDA notebooks collected online. A user study is conducted\
    \ to investigate both EDAssistant and data scientists\u2019 current practice (i.e.,\
    \ using external search engines). The results demonstrate the effectiveness and\
    \ usefulness of EDAssistant, and participants appreciated its smooth and in-context\
    \ support of EDA. We also report several design implications regarding code recommendation\
    \ tools."
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: edassistant
  otherURLs: []
  paperURL: https://dl.acm.org/doi/abs/10.1145/3545995?casa_token=xZ3rdEMx9FAAAAAA:0i0ZuQX7M_gUMzBlOyh84uEsNdSP-ZEtk2yzuSObWb2Js9UQSXt5j9Doc0dmSKPD8RDjMmGaR2CHhg
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@mastersthesis{lauNbinteractGenerateInteractive2018,\n  title = {Nbinteract:\
    \ Generate Interactive Web Pages from {{Jupyter}} Notebooks},\n  author = {Lau,\
    \ Samuel and Hug, Joshua},\n  year = {2018},\n  school = {University of California\
    \ at Berkeley}\n}\n"
  communication: ''
  description: "Nbinteract provides a Python library and a command-line tool to convert\
    \ Jupyter notebooks to standalone, interactive HTML web pages. These web pages\
    \ may be viewed by any web browser running JavaScript, regardlessof whether the\
    \ viewer has Python or Jupyter installed locally. nbinteract\u2019s built-in support\
    \ for function-driven plotting makes interactive visualizations simpler to create\
    \ by allowing authors to focus on declarative data changes in- stead of callbacks.\
    \ nbinteract has use cases for data analysis, visualization, and especially education,\
    \ where it is used for a prominent textbook on data science."
  githubURL: https://github.com/SamLau95/nbinteract
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: nbinteract
  otherURLs: []
  paperURL: https://digitalassets.lib.berkeley.edu/techreports/ucb/text/EECS-2018-57.pdf
  releaseYear: 2018
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{yuVizicJupyterbasedInteractive2017,\n  title = {Vizic: {{A Jupyter-based}}\
    \ Interactive Visualization Tool for Astronomical Catalogs},\n  shorttitle = {Vizic},\n\
    \  author = {Yu, W. and Carrasco Kind, M. and Brunner, R.J.},\n  year = {2017},\n\
    \  journal = {Astronomy and Computing},\n  volume = {20},\n  doi = {10.1016/j.ascom.2017.06.004},\n\
    \  url = {https://linkinghub.elsevier.com/retrieve/pii/S2213133716301500},\n \
    \ urldate = {2023-04-24},\n  langid = {english}\n}\n"
  communication: ''
  description: The ever-growing datasets in observational astronomy have challenged
    scientists in many aspects, including an efficient and interactive data exploration
    and visualization. Many tools have been developed to confront this challenge.
    However, they usually focus on displaying the actual images or focus on visualizing
    patterns within catalogs in a predefined way. In this paper we introduce Vizic,
    a Python visualization library that builds the connection between images and catalogs
    through an interactive map of the sky region. Vizic visualizes catalog data over
    a custom background canvas using the shape, size and orientation of each object
    in the catalog. The displayed objects in the map are highly interactive and customizable
    comparing to those in the observation images. These objects can be filtered by
    or colored by their property values, such as redshift and magnitude. They also
    can be sub-selected using a lasso-like tool for further analysis using standard
    Python functions and everything is done from inside a Jupyter notebook. Furthermore,
    Vizic allows custom overlays to be appended dynamically on top of the sky map.
    We have initially implemented several overlays, namely, Voronoi, Delaunay, Minimum
    Spanning Tree and HEALPix grid layer, which are helpful for visualizing large-scale
    structure. All these overlays can be generated, added or removed interactively
    with just one line of code. The catalog data is stored in a non-relational database,
    and the interfaces have been developed in JavaScript and Python to work within
    Jupyter Notebook, which allows to create customizable widgets, user generated
    scripts to analyze and plot the data selected/displayed in the interactive map.
    This unique design makes Vizic a very powerful and flexible interactive analysis
    tool. Vizic can be adopted in variety of exercises, for example, data inspection,
    clustering analysis, galaxy alignment studies, outlier identification or just
    large scale visualizations.
  githubURL: https://github.com/ywx649999311/vizic
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: vizic
  otherURLs: []
  paperURL: https://www.sciencedirect.com/science/article/pii/S2213133716301500?casa_token=YymkOTIrOHYAAAAA:V6RiDRh3j1BDIvnSwIEEit0j2JSrDbNtW8dcGBBrrHFuV2qismMPDr4Mfv2ZuIksR6pPIRWCiBk
  releaseYear: 2017
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{rosenthalInteractiveNetworkVisualization2018,\n  title = {Interactive\
    \ Network Visualization in {{Jupyter}} Notebooks: {{visJS2jupyter}}},\n  shorttitle\
    \ = {Interactive Network Visualization in {{Jupyter}} Notebooks},\n  author =\
    \ {Rosenthal, Sara Brin and Len, Julia and Webster, Mikayla and Gary, Aaron and\
    \ Birmingham, Amanda and Fisch, Kathleen M},\n  year = {2018},\n  journal = {Bioinformatics},\n\
    \  volume = {34},\n  doi = {10.1093/bioinformatics/btx581},\n  url = {https://academic.oup.com/bioinformatics/article/34/1/126/4158037},\n\
    \  urldate = {2023-04-04},\n  langid = {english}\n}\n"
  communication: ''
  description: Network biology is widely used to elucidate mechanisms of disease and
    biological processes. The ability to interact with biological networks is important
    for hypothesis generation and to give researchers an intuitive understanding of
    the data. We present visJS2jupyter, a tool designed to embed interactive networks
    in Jupyter notebooks to streamline network analysis and to promote reproducible
    research. The tool provides functions for performing and visualizing useful network
    operations in biology, including network overlap, network propagation around a
    focal set of genes, and co-localization of two sets of seed genes. visJS2jupyter
    uses the JavaScript library vis.js to create interactive networks displayed within
    Jupyter notebook cells with features including drag, click, hover, and zoom. We
    demonstrate the functionality of visJS2jupyter applied to a biological question,
    by creating a network propagation visualization to prioritize risk-related genes
    in autism. The visJS2jupyter package is distributed under the MIT License. The
    source code, documentation and installation instructions are freely available
    on GitHub at https://github.com/ucsd-ccbb/visJS2jupyter. The package can be downloaded
    at https://pypi.python.org/pypi/visJS2jupyter.
  githubURL: https://github.com/ucsd-ccbb/visJS2jupyter
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: visjs2jupyter
  otherURLs: []
  paperURL: https://academic.oup.com/bioinformatics/article-abstract/34/1/126/4158037
  releaseYear: 2018
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{vanderplasAltairInteractiveStatistical2018,\n  title = {Altair:\
    \ {{Interactive Statistical Visualizations}} for {{Python}}},\n  shorttitle =\
    \ {Altair},\n  author = {VanderPlas, Jacob and Granger, Brian and Heer, Jeffrey\
    \ and Moritz, Dominik and Wongsuphasawat, Kanit and Satyanarayan, Arvind and Lees,\
    \ Eitan and Timofeev, Ilia and Welsh, Ben and Sievert, Scott},\n  year = {2018},\n\
    \  journal = {Journal of Open Source Software},\n  volume = {3},\n  doi = {10.21105/joss.01057},\n\
    \  url = {http://joss.theoj.org/papers/10.21105/joss.01057},\n  urldate = {2023-04-13}\n\
    }\n"
  communication: ''
  description: Altair is a declarative statistical visualization library for Python.
    Statistical visualization is a constrained subset of data visualization focused
    on the creation of visualizations that are helpful in statistical modeling. The
    constrained model of statistical visualization is usually expressed in terms of
    a visualization grammar that specifies how input data is transformed and mapped
    to visual properties .
  githubURL: https://github.com/altair-viz/altair
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: altair
  otherURLs: []
  paperURL: http://www.theoj.org/joss-papers/joss.01057/10.21105.joss.01057.pdf
  releaseYear: 2018
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{nguyenNGLviewInteractiveMolecular2018,\n  title = {{{NGLview}}\\\
    textendash Interactive Molecular Graphics for {{Jupyter}} Notebooks},\n  author\
    \ = {Nguyen, Hai and Case, David A and Rose, Alexander S},\n  year = {2018},\n\
    \  journal = {Bioinformatics},\n  volume = {34},\n  doi = {10.1093/bioinformatics/btx789},\n\
    \  url = {https://academic.oup.com/bioinformatics/article/34/7/1241/4721781},\n\
    \  urldate = {2023-04-14},\n  langid = {english}\n}\n"
  communication: ''
  description: NGLview is a Jupyter/IPython widget to interactively view molecular
    structures as well as trajectories from molecular dynamics simulations. Fast and
    scalable molecular graphics are provided through the NGL Viewer. The widget supports
    showing data from the file-system, online data bases and from objects of many
    popular analysis libraries including mdanalysis, mdtraj, pytraj, rdkit and more.
    The source code is freely available under the MIT license at https://github.com/arose/nglview.
    Python packages are available from PyPI and bioconda. NGLview uses Python on the
    server-side and JavaScript on the client. The integration with Jupyter is done
    through the ipywidgets package. The NGL Viewer is embedded client-side to provide
    WebGL accelerated molecular graphics.
  githubURL: https://github.com/nglviewer/nglview
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: nglview
  otherURLs: []
  paperURL: https://academic.oup.com/bioinformatics/article-abstract/34/7/1241/4721781
  releaseYear: 2018
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@techreport{pielawskiTissUUmapsImprovementsInteractive2022,\n  type = {Preprint},\n\
    \  title = {{{TissUUmaps}} 3: {{Improvements}} in Interactive Visualization, Exploration,\
    \ and Quality Assessment of Large-Scale Spatial Omics Data},\n  shorttitle = {{{TissUUmaps}}\
    \ 3},\n  author = {Pielawski, Nicolas and Andersson, Axel and Avenel, Christophe\
    \ and Behanova, Andrea and Chelebian, Eduard and Klemm, Anna and Nysj{\\\"o},\
    \ Fredrik and Solorzano, Leslie and W{\\\"a}hlby, Carolina},\n  year = {2022},\n\
    \  institution = {{Bioinformatics}},\n  doi = {10.1101/2022.01.28.478131},\n \
    \ url = {http://biorxiv.org/lookup/doi/10.1101/2022.01.28.478131},\n  urldate\
    \ = {2023-04-04},\n  langid = {english}\n}\n"
  communication: ''
  description: "Background and Objectives Spatially resolved techniques for exploring\
    \ the molecular landscape of tissue samples, such as spatial transcriptomics,\
    \ often result in millions of data points and images too large to view on a regular\
    \ desktop computer, limiting the possibilities in visual interactive data exploration.\
    \ TissUUmaps is a free, open-source browser-based tool for GPU-accelerated visualization\
    \ and interactive exploration of 107+ data points overlaying tissue samples. Methods\
    \ Herein we describe how TissUUmaps 3 provides instant multiresolution image viewing\
    \ and can be customized, shared, and also integrated into Jupyter Notebooks. We\
    \ introduce new modules where users can visualize markers and regions, explore\
    \ spatial statistics, perform quantitative analyses of tissue morphology, and\
    \ assess the quality of decoding in situ transcriptomics data. Results We show\
    \ that thanks to targeted optimizations the time and cost associated with interactive\
    \ data exploration were reduced, enabling TissUUmaps 3 to handle the scale of\
    \ today\u2019s spatial transcriptomics methods. Conclusion TissUUmaps 3 provides\
    \ significantly improved performance for large multiplex datasets as compared\
    \ to previous versions. We envision TissUUmaps to contribute to broader dissemination\
    \ and flexible sharing of large-scale spatial omics data."
  githubURL: https://github.com/TissUUmaps/TissUUmapsCore
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: tissuumaps
  otherURLs: []
  paperURL: https://www.biorxiv.org/content/10.1101/2022.01.28.478131.abstract
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{fernandezClustergrammerWebbasedHeatmap2017,\n  title = {Clustergrammer,\
    \ a Web-Based Heatmap Visualization and Analysis Tool for High-Dimensional Biological\
    \ Data},\n  author = {Fernandez, Nicolas F. and Gundersen, Gregory W. and Rahman,\
    \ Adeeb and Grimes, Mark L. and Rikova, Klarisa and Hornbeck, Peter and Ma'ayan,\
    \ Avi},\n  year = {2017},\n  journal = {Scientific Data},\n  volume = {4},\n \
    \ doi = {10.1038/sdata.2017.151},\n  url = {https://www.nature.com/articles/sdata2017151},\n\
    \  urldate = {2023-04-04},\n  langid = {english}\n}\n"
  communication: ''
  description: 'Most tools developed to visualize hierarchically clustered heatmaps
    generate static images. Clustergrammer is a web-based visualization tool with
    interactive features such as: zooming, panning, filtering, reordering, sharing,
    performing enrichment analysis, and providing dynamic gene annotations. Clustergrammer
    can be used to generate shareable interactive visualizations by uploading a data
    table to a web-site, or by embedding Clustergrammer in Jupyter Notebooks. The
    Clustergrammer core libraries can also be used as a toolkit by developers to generate
    visualizations within their own applications. Clustergrammer is demonstrated using
    gene expression data from the cancer cell line encyclopedia (CCLE), original post-translational
    modification data collected from lung cancer cells lines by a mass spectrometry
    approach, and original cytometry by time of flight (CyTOF) single-cell proteomics
    data from blood. Clustergrammer enables producing interactive web based visualizations
    for the analysis of diverse biological data.'
  githubURL: https://github.com/MaayanLab/clustergrammer
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: clustergrammar
  otherURLs: []
  paperURL: https://www.nature.com/articles/sdata2017151
  releaseYear: 2017
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{perroneNetworkVisualizationsPyvis2020,\n  title = {Network Visualizations\
    \ with {{Pyvis}} and {{VisJS}}},\n  author = {Perrone, Giancarlo and Unpingco,\
    \ Jose and Lu, Haw-minn},\n  year = {2020},\n  url = {http://arxiv.org/abs/2006.04951},\n\
    \  urldate = {2023-04-04},\n  archiveprefix = {arxiv},\n  journal = {2006.04951}\n\
    }\n"
  communication: ''
  description: Pyvis is a Python module that enables visualizing and interactively
    manipulating network graphs in the Jupyter notebook, or as a standalone web application.
    Pyvis is built on top of the powerful and mature VisJS JavaScript library, which
    allows for fast and responsive interactions while also abstracting away the low-level
    JavaScript and HTML. This means that elements of the rendered graph visualization,
    such as node/edge attributes can be specified within Python and shipped to the
    JavaScript layer for VisJS to render. This declarative approach makes it easy
    to quickly explore graph visualizations and investigate data relationships. In
    addition, Pyvis is highly customizable so that colors, sizes, and hover tooltips
    can be assigned to the rendered graph. The network graph layout is controlled
    by a front-end physics engine that is configurable from a Python interface, allowing
    for the detailed placement of the graph elements. In this paper, we outline use
    cases for Pyvis with specific examples to highlight key features for any analysis
    workflow. A brief overview of Pyvis' implementation describes how the Python front-end
    binding uses simple Pyvis calls.
  githubURL: https://github.com/WestHealth/pyvis
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pyvis
  otherURLs: []
  paperURL: https://arxiv.org/abs/2006.04951
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{chenPI2EndtoendInteractive2022,\n  title = {{{PI2}}: {{End-to-end\
    \ Interactive Visualization Interface Generation}} from {{Queries}}},\n  shorttitle\
    \ = {{{PI2}}},\n  booktitle = {Proceedings of the 2022 {{International Conference}}\
    \ on {{Management}} of {{Data}}},\n  author = {Chen, Yiru and Wu, Eugene},\n \
    \ year = {2022},\n  doi = {10.1145/3514221.3526166},\n  url = {https://dl.acm.org/doi/10.1145/3514221.3526166},\n\
    \  urldate = {2023-04-04},\n  langid = {english}\n}\n"
  communication: ''
  description: Interactive visualization interfaces are critical in data analysis.
    Yet creating new interfaces is challenging, as the developer must understand the
    queries needed for the desired analysis task, and then design the appropriate
    interface. Existing task models are too abstract to be used to automatically generate
    interfaces, and visualization recommenders do not take the queries nor interactions
    into account. PI2 is the first system to generate fully functional interactive
    visualization interfaces from a representative sequence of task queries. PI2 analyzes
    queries syntactically and proposes a novel Difftree representation that encodes
    the systematic variations between query abstract syntax trees. PI2 then poses
    interface generation as a schema mapping problem from each Difftree to a visualization
    that renders its results, and the variations encoded in each Difftree to interactions
    in the interface. Interface generation further takes the layout and screen size
    into account. Our user studies show that PI2 interfaces are comparable to or better
    than those designed by developers, and that PI2 can generate exploration interfaces
    that are easier to use than the state-of-the-art SQL notebook products. What's
    more, PI2 generates high-quality interfaces within a few seconds.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pi2
  otherURLs: []
  paperURL: https://dl.acm.org/doi/pdf/10.1145/3514221.3520153
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{simonneGwaihirJupyterNotebook2022,\n  title = {{\\emph{Gwaihir}}\
    \ : {{{\\emph{Jupyter Notebook}}}} Graphical User Interface for {{Bragg}} Coherent\
    \ Diffraction Imaging},\n  shorttitle = {{\\emph{Gwaihir}}},\n  author = {Simonne,\
    \ David and Carnis, J{\\'e}r{\\^o}me and Atlan, Cl{\\'e}ment and Chatelier, Corentin\
    \ and {Favre-Nicolin}, Vincent and Dupraz, Maxime and Leake, Steven J. and Zatterin,\
    \ Edoardo and Resta, Andrea and Coati, Alessandro and Richard, Marie-Ingrid},\n\
    \  year = {2022},\n  journal = {Journal of Applied Crystallography},\n  volume\
    \ = {55},\n  doi = {10.1107/S1600576722005854},\n  url = {https://scripts.iucr.org/cgi-bin/paper?S1600576722005854},\n\
    \  urldate = {2023-04-04}\n}\n"
  communication: ''
  description: Bragg coherent X-ray diffraction is a nondestructive method for probing
    material structure in three dimensions at the nanoscale, with unprecedented resolution
    in displacement and strain fields. This work presents Gwaihir, a user-friendly
    and open-source tool to process and analyze Bragg coherent X-ray diffraction data.
    It integrates the functionalities of the existing packages bcdi and PyNX in the
    same toolbox, creating a natural workflow and promoting data reproducibility.
    Its graphical interface, based on Jupyter Notebook widgets, combines an interactive
    approach for data analysis with a powerful environment designed to link large-scale
    facilities and scientists.
  githubURL: https://github.com/DSimonne/gwaihir
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: gwaihir
  otherURLs: []
  paperURL: https://scripts.iucr.org/cgi-bin/paper?te5096
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{keryMageFluidMoves2020,\n  title = {Mage: {{Fluid Moves\
    \ Between Code}} and {{Graphical Work}} in {{Computational Notebooks}}},\n  shorttitle\
    \ = {Mage},\n  booktitle = {Proceedings of the 33rd {{Annual ACM Symposium}} on\
    \ {{User Interface Software}} and {{Technology}}},\n  author = {Kery, Mary Beth\
    \ and Ren, Donghao and Hohman, Fred and Moritz, Dominik and Wongsuphasawat, Kanit\
    \ and Patel, Kayur},\n  year = {2020},\n  doi = {10.1145/3379337.3415842},\n \
    \ url = {https://dl.acm.org/doi/10.1145/3379337.3415842},\n  urldate = {2021-09-15},\n\
    \  langid = {english}\n}\n"
  communication: ''
  description: We aim to increase the flexibility at which a data worker can choose
    the right tool for the job, regardless of whether the tool is a code library or
    an interactive graphical user interface (GUI). To achieve this flexibility, we
    extend computational notebooks with a new API mage, which supports tools that
    can represent themselves as both code and GUI as needed. We discuss the design
    of mage as well as design opportunities in the space of flexible code/GUI tools
    for data work. To understand tooling needs, we conduct a study with nine professional
    practitioners and elicit their feedback on mage and potential areas for flexible
    code/GUI tooling. We then implement six client tools for mage that illustrate
    the main themes of our study findings. Finally, we discuss open challenges in
    providing flexible code/GUI interactions for data workers.
  githubURL: https://github.com/magefile/mage
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: mage
  otherURLs: []
  paperURL: https://dl.acm.org/doi/abs/10.1145/3379337.3415842
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{crockettIvpyIconographicVisualization2021,\n  title = {Ivpy: {{Iconographic\
    \ Visualization Inside Computational Notebooks}}},\n  author = {Crockett, Damon},\n\
    \  year = {2021},\n  journal = {International Journal for Digital Art History},\n\
    \  doi = {10.11588/DAH.2019.4.66401},\n  url = {https://journals.ub.uni-heidelberg.de/index.php/dah/article/view/66401},\n\
    \  urldate = {2023-04-24},\n  langid = {english}\n}\n"
  communication: ''
  description: Iconographic Visualization in Python, or ivpy, is a software module,
    written in the Python programming language, that provides a set of functions for
    organizing iconographic representations of data, including images and glyphs.
    The module also provides methods for extracting visual features from images; generating
    and hand-tuning clusters of data points; and embedding high-dimensional data in
    2D coordinate spaces. It is designed for use inside computational notebooks, so
    that users working with data needn't leave the notebook environment in order to
    generate visualizations. The software is designed primarily for those researchers
    working with large image datasets in fields where human visual expertise cannot
    be replaced with or superseded by machine vision, such as art history and media
    studies.
  githubURL: https://github.com/damoncrockett/ivpy
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: ivpy
  otherURLs: []
  paperURL: https://journals.ub.uni-heidelberg.de/index.php/dah/article/view/66401
  releaseYear: 2021
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{wangTimberTrekExploringCurating2022,\n  title = {{{TimberTrek}}:\
    \ {{Exploring}} and {{Curating Sparse Decision Trees}} with {{Interactive Visualization}}},\n\
    \  shorttitle = {{{TimberTrek}}},\n  booktitle = {2022 {{IEEE Visualization}}\
    \ and {{Visual Analytics}} ({{VIS}})},\n  author = {Wang, Zijie J. and Zhong,\
    \ Chudi and Xin, Rui and Takagi, Takuya and Chen, Zhi and Chau, Duen Horng and\
    \ Rudin, Cynthia and Seltzer, Margo},\n  year = {2022},\n  doi = {10.1109/VIS54862.2022.00021},\n\
    \  url = {https://ieeexplore.ieee.org/document/9973202/},\n  urldate = {2023-01-26}\n\
    }\n"
  communication: ''
  description: 'Given thousands of equally accurate machine learning (ML) models,
    how can users choose among them? A recent ML technique enables domain experts
    and data scientists to generate a complete Rashomon set for sparse decision trees-a
    huge set of almost-optimal inter-pretable ML models. To help ML practitioners
    identify models with desirable properties from this Rashomon set, we develop Tim-bertrek,
    the first interactive visualization system that summarizes thousands of sparse
    decision trees at scale. Two usage scenarios high-light how Timbertrek can empower
    users to easily explore, compare, and curate models that align with their domain
    knowledge and values. Our open-source tool runs directly in users'' computational
    notebooks and web browsers, lowering the barrier to creating more responsible
    ML models. Timbertrek is available at the following public demo link: https: //poloclub.
    github. io/timbertrek.'
  githubURL: https://github.com/poloclub/timbertrek
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: timbertrek
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/abstract/document/9973202/?casa_token=hsSE6q496VsAAAAA:RWHvwh_lulaE2FKfbNiATEZ3sBsy3HvIpY_Cez5ajt3TC7u2T0K-sOIYfqLh_WTfxqN3h9L_oQ
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{munechikaVisualAuditorInteractive2022,\n  title = {Visual\
    \ {{Auditor}}: {{Interactive Visualization}} for {{Detection}} and {{Summarization}}\
    \ of {{Model Biases}}},\n  booktitle = {2022 {{IEEE Visualization Conference}}\
    \ ({{VIS}})},\n  author = {Munechika, David and Wang, Zijie J. and Reidy, Jack\
    \ and Rubin, Josh and Gade, Krishna and Kenthapadi, Krishnaram and Chau, Duen\
    \ Horng},\n  year = {2022},\n  urldate = {2022-06-19}\n}\n"
  communication: ''
  description: As machine learning (ML) systems become increasingly widespread, it
    is necessary to audit these systems for biases prior to their de-ployment. Recent
    research has developed algorithms for effectively identifying intersectional bias
    in the form of interpretable, underper-forming subsets (or slices) of the data.
    However, these solutions and their insights are limited without a tool for visually
    understanding and interacting with the results of these algorithms. We propose
    Visual Auditor, an interactive visualization tool for auditing and summarizing
    model biases. Visual Auditor assists model validation by providing an interpretable
    overview of intersectional bias (bias that is present when examining populations
    defined by multiple features), details about relationships between problematic
    data slices, and a comparison between underperforming and overper-forming data
    slices in a model. Our open-source tool runs directly in both computational notebooks
    and web browsers, making model auditing accessible and easily integrated into
    current ML development workflows. An observational user study in collaboration
    with domain experts at Fiddler AI highlights that our tool can help ML practitioners
    identify and understand model biases.
  githubURL: https://github.com/poloclub/visual-auditor
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: visual-auditor
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/abstract/document/9973204/?casa_token=yV4qNZ1nKtgAAAAA:IbRgePfyZOXzZ-lI00Z4e1X0x18Pg8eWtdjqySmPfN8GG-jKsiihsca3Zf4ciht5OJA8clk21w
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{wangInterpretabilityThenWhat2022,\n  title = {Interpretability,\
    \ {{Then What}}? {{Editing Machine Learning Models}} to {{Reflect Human Knowledge}}\
    \ and {{Values}}},\n  booktitle = {Proceedings of the 28th {{ACM SIGKDD Conference}}\
    \ on {{Knowledge Discovery}} and {{Data Mining}}},\n  author = {Wang, Zijie J.\
    \ and Kale, Alex and Nori, Harsha and Stella, Peter and Nunnally, Mark E. and\
    \ Chau, Duen Horng and Vorvoreanu, Mihaela and Wortman Vaughan, Jennifer and Caruana,\
    \ Rich},\n  year = {2022},\n  series = {{{KDD}} '22},\n  doi = {10.1145/3534678.3539074},\n\
    \  url = {https://doi.org/10.1145/3534678.3539074}\n}\n"
  communication: ''
  description: Recent strides in interpretable machine learning (ML) research reveal
    that models exploit undesirable patterns in the data to make predictions, which
    potentially causes harms in deployment. However, it is unclear how we can fix
    these models. We present our ongoing work, GAM Changer, an open-source interactive
    system to help data scientists and domain experts easily and responsibly edit
    their Generalized Additive Models (GAMs). With novel visualization techniques,
    our tool puts interpretability into action -- empowering human users to analyze,
    validate, and align model behaviors with their knowledge and values. Built using
    modern web technologies, our tool runs locally in users' computational notebooks
    or web browsers without requiring extra compute resources, lowering the barrier
    to creating more responsible ML models. GAM Changer is available at this https
    URL.
  githubURL: https://github.com/interpretml/gam-changer
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: gam-changer
  otherURLs: []
  paperURL: https://arxiv.org/abs/2112.03245
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{sivaramanEmblazeIlluminatingMachine2022,\n  title = {Emblaze:\
    \ {{Illuminating Machine Learning Representations}} through {{Interactive Comparison}}\
    \ of {{Embedding Spaces}}},\n  shorttitle = {Emblaze},\n  booktitle = {27th {{International\
    \ Conference}} on {{Intelligent User Interfaces}}},\n  author = {Sivaraman, Venkatesh\
    \ and Wu, Yiwei and Perer, Adam},\n  year = {2022},\n  doi = {10.1145/3490099.3511137},\n\
    \  url = {https://dl.acm.org/doi/10.1145/3490099.3511137},\n  urldate = {2023-02-14},\n\
    \  langid = {english}\n}\n"
  communication: ''
  description: Modern machine learning techniques commonly rely on complex, high-dimensional
    embedding representations to capture underlying structure in the data and improve
    performance. In order to characterize model flaws and choose a desirable representation,
    model builders often need to compare across multiple embedding spaces, a challenging
    analytical task supported by few existing tools. We first interviewed nine embedding
    experts in a variety of fields to characterize the diverse challenges they face
    and techniques they use when analyzing embedding spaces. Informed by these perspectives,
    we developed a novel system called Emblaze that integrates embedding space comparison
    within a computational notebook environment. Emblaze uses an animated, interactive
    scatter plot with a novel Star Trail augmentation to enable visual comparison.
    It also employs novel neighborhood analysis and clustering procedures to dynamically
    suggest groups of points with interesting changes between spaces. Through a series
    of case studies with ML experts, we demonstrate how interactive comparison with
    Emblaze can help gain new insights into embedding space structure.
  githubURL: https://github.com/cmudig/emblaze
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: emblaze
  otherURLs: []
  paperURL: https://arxiv.org/pdf/2202.02641.pdf
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{graserExploringMovementData2020,\n  title = {Exploring Movement\
    \ Data in Notebook Environments},\n  booktitle = {{{IEEE VIS}} 2020 Workshop on\
    \ Information Visualization of Geospatial Networks, Flows and Movement ({{MoVis}})},\n\
    \  author = {Graser, Anita and Dragaschnig, Melitta},\n  year = {2020}\n}\n"
  communication: ''
  description: Notebooks environments have become popular for data analysis but their
    default visualization capabilities are limited. We present ongoing work on the
    open geospatial library MovingPandas that enables the exploration of movement
    data in notebooks.
  githubURL: https://github.com/movingpandas/movingpandas
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: moving-pandas
  otherURLs: []
  paperURL: http://move.geog.ucsb.edu/wp-content/uploads/2020/10/MoVIS20_paper_4.pdf
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{vanderdoncktPlotlyResamplerEffectiveVisual2022,\n  title\
    \ = {Plotly-{{Resampler}}: {{Effective Visual Analytics}} for {{Large Time Series}}},\n\
    \  shorttitle = {Plotly-{{Resampler}}},\n  booktitle = {2022 {{IEEE Visualization}}\
    \ and {{Visual Analytics}} ({{VIS}})},\n  author = {Van Der Donckt, Jonas and\
    \ {Van der Donckt}, Jeroen and Deprost, Emiel and Van Hoecke, Sofie},\n  year\
    \ = {2022},\n  doi = {10.1109/VIS54862.2022.00013},\n  url = {https://ieeexplore.ieee.org/document/9973221/},\n\
    \  urldate = {2023-04-04}\n}\n"
  communication: ''
  description: Visual analytics is arguably the most important step in getting acquainted
    with your data. This is especially the case for time series, as this data type
    is hard to describe and cannot be fully understood when using for example summary
    statistics. To realize effective time series visualization, four requirements
    have to be met; a tool should be (1) interactive, (2) scalable to millions of
    data points, (3) integrable in conventional data science environments, and (4)
    highly configurable. We observe that open source Python visualization toolkits
    empower data scientists in most visual analytics tasks, but lack the combination
    of scalability and interactivity to realize effective time series visualization.
    As a means to facilitate these requirements, we created Plotly-Resampler, an open
    source Python library. Plotly-Resampler is an add-on for Plotly's Python bindings,
    enhancing line chart scalability on top of an interactive toolkit by aggregating
    the underlying data depending on the current graph view. Plotly-Resampler is built
    to be snappy, as the reactivity of a tool qualitatively affects how analysts visually
    explore and analyze data. A benchmark task highlights how our toolkit scales better
    than alternatives in terms of number of samples and time series. Additionally,
    Plotly-Resampler's flexible data aggregation functionality paves the path towards
    researching novel aggregation techniques. Plotly-Resampler's integrability, together
    with its configurability, convenience, and high scalability, allows to effectively
    analyze high-frequency data in your day-to-day Python environment.
  githubURL: https://github.com/predict-idlab/plotly-resampler
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: plotly-resampler
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/abstract/document/9973221?casa_token=WraofwTUaNIAAAAA:fAYaVjTej4JZYpI34fgQnMYhkQEpp-KLOP7I9g9FhUn6LDnQiTFhL9uT0pSIk6_kDHxArMwlNw
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{bayrakPRAGMAInteractivelyConstructing2020,\n  title = {{{PRAGMA}}:\
    \ {{Interactively Constructing Functional Brain Parcellations}}},\n  shorttitle\
    \ = {{{PRAGMA}}},\n  booktitle = {2020 {{IEEE Visualization Conference}} ({{VIS}})},\n\
    \  author = {Bayrak, Roza G. and Hoang, Nhung and Hansen, Colin B. and Chang,\
    \ Catie and Berger, Matthew},\n  year = {2020},\n  doi = {10.1109/VIS47514.2020.00016},\n\
    \  url = {https://ieeexplore.ieee.org/document/9331292/},\n  urldate = {2023-04-04}\n\
    }\n"
  communication: ''
  description: A prominent goal of neuroimaging studies is mapping the human brain,
    in order to identify and delineate functionally-meaningful regions and elucidate
    their roles in cognitive behaviors. These brain regions are typically represented
    by atlases that capture general trends over large populations. Despite being indispensable
    to neuroimaging experts, population-level atlases do not capture individual differences
    in functional organization. In this work, we present an interactive visualization
    method, PRAGMA, that allows domain experts to derive scan-specific parcellations
    from established atlases. PRAGMA features a user-driven, hierarchical clustering
    scheme for defining temporally correlated parcels in varying granularity. The
    visualization design supports the user in making decisions on how to perform clustering,
    namely when to expand, collapse, or merge parcels. This is accomplished through
    a set of linked and coordinated views for understanding the user's current hierarchy,
    assessing intra-cluster variation, and relating parcellations to an established
    atlas. We assess the effectiveness of PRAGMA through a user study with four neuroimaging
    domain experts, where our results show that PRAGMA shows the potential to enable
    exploration of individualized and state-specific brain parcellations and to offer
    interesting insights into functional brain networks.
  githubURL: https://github.com/neurdylab/PRAGMA
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pragma
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9331292
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{guoVAINEVisualizationAI2021,\n  title = {{{VAINE}}: {{Visualization}}\
    \ and {{AI}} for {{Natural Experiments}}},\n  shorttitle = {{{VAINE}}},\n  booktitle\
    \ = {2021 {{IEEE Visualization Conference}} ({{VIS}})},\n  author = {Guo, Grace\
    \ and Glenski, Maria and Shaw, ZhuanYi and Saldanha, Emily and Endert, Alex and\
    \ Volkova, Svitlana and Arendt, Dustin},\n  year = {2021},\n  doi = {10.1109/VIS49827.2021.9623285},\n\
    \  url = {https://ieeexplore.ieee.org/document/9623285/},\n  urldate = {2023-04-04}\n\
    }\n"
  communication: ''
  description: "Natural experiments are observational studies where the assignment\
    \ of treatment conditions to different populations occurs by chance\u201Cin the\
    \ wild\u201D. Researchers from fields such as economics, healthcare, and the social\
    \ sciences leverage natural experiments to conduct hypothesis testing and causal\
    \ effect estimation for treatment and outcome variables that would otherwise be\
    \ costly, infeasible, or unethical. In this paper, we introduce VAINE (Visualization\
    \ and AI for Natural Experiments), a visual analytics tool for identifying and\
    \ understanding natural experiments from observational data. We then demonstrate\
    \ how VAINE can be used to validate causal relationships, estimate average treatment\
    \ effects, and identify statistical phenomena such as Simpson\u2019s paradox through\
    \ two usage scenarios."
  githubURL: https://github.com/pnnl/vaine-widget
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: vaine
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/abstract/document/9623285
  releaseYear: 2021
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{tritsarolisSTVISIONSPython2021,\n  title = {{{ST}}\\_{{VISIONS}}:\
    \ {{A Python Library}} for {{Interactive Visualization}} of {{Spatio-temporal\
    \ Data}}},\n  shorttitle = {{{ST}}\\_{{VISIONS}}},\n  booktitle = {2021 22nd {{IEEE\
    \ International Conference}} on {{Mobile Data Management}} ({{MDM}})},\n  author\
    \ = {Tritsarolis, Andreas and Doulkeridis, Christos and Pelekis, Nikos and Theodoridis,\
    \ Yannis},\n  year = {2021},\n  doi = {10.1109/MDM52706.2021.00048},\n  url =\
    \ {https://ieeexplore.ieee.org/document/9474850/},\n  urldate = {2023-04-04}\n\
    }\n"
  communication: ''
  description: In this demo paper we present ST_VISIONS, an easy-to-use Python library
    for interactive visualizations of spatial and spatio-temporal datasets. By automating
    the low-level details of the underlying visualization library (Bokeh), ST_VISIONS
    allows data scientists to create interactive, map-based visualizations, by writing
    Python code at a higher level of abstraction. Consequently, we accelerate the
    task of visualization from different sources, while we support interactive filtering,
    colorization, as well as multiple graphs, for various types of spatial and spatio-temporal
    data.
  githubURL: https://github.com/DataStories-UniPi/ST-Visions
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: st-visions
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/abstract/document/9474850?casa_token=6d2QxiLNRbQAAAAA:mCfkCx_ON1LSn4NwunSlCghXBtIbrZLyqPdEKkaTfO0BIevnIfwJsndmdOWe_PCTtpMzSVJRlg
  releaseYear: 2021
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{lageStatCastDashboardExploration2016,\n  title = {{{StatCast Dashboard}}:\
    \ {{Exploration}} of {{Spatiotemporal Baseball Data}}},\n  shorttitle = {{{StatCast\
    \ Dashboard}}},\n  author = {Lage, Marcos and Ono, Jorge Piazentin and Cervone,\
    \ Daniel and Chiang, Justin and Dietrich, Carlos and Silva, Claudio T.},\n  year\
    \ = {2016},\n  journal = {IEEE Computer Graphics and Applications},\n  volume\
    \ = {36},\n  doi = {10.1109/MCG.2016.101},\n  url = {https://ieeexplore.ieee.org/document/7579419/},\n\
    \  urldate = {2023-04-16}\n}\n"
  communication: ''
  description: This article presents a visualization and analytics infrastructure
    to help query and facilitate the analysis of this new tracking data. The goal
    is to go beyond descriptive statistics of individual plays, allowing analysts
    to study diverse collections of games and game events. The StatCast Dashboard
    visual interface helps users query, filter, and analyze the tracking data gathered
    by the Major League Baseball (MLB) StatCast spatiotemporal data-tracking system.
    The proposed system enables the exploration of the data using a simple querying
    interface and a set of flexible interactive visualization tools.
  githubURL: https://github.com/uwdk/statcast_dashboard
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: statcast-dashboard
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/document/7579419
  releaseYear: 2016
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{onoPipelineProfilerVisualAnalytics2021,\n  title = {{{PipelineProfiler}}:\
    \ {{A Visual Analytics Tool}} for the {{Exploration}} of {{AutoML Pipelines}}},\n\
    \  shorttitle = {{{{\\emph{PipelineProfiler}}}}},\n  author = {Ono, Jorge Piazentin\
    \ and Castelo, Sonia and Lopez, Roque and Bertini, Enrico and Freire, Juliana\
    \ and Silva, Claudio},\n  year = {2021},\n  journal = {IEEE Transactions on Visualization\
    \ and Computer Graphics},\n  volume = {27},\n  doi = {10.1109/TVCG.2020.3030361},\n\
    \  url = {https://ieeexplore.ieee.org/document/9222086/},\n  urldate = {2022-08-29}\n\
    }\n"
  communication: ''
  description: In recent years, a wide variety of automated machine learning (AutoML)
    methods have been proposed to generate end-to-end ML pipelines. While these techniques
    facilitate the creation of models, given their black-box nature, the complexity
    of the underlying algorithms, and the large number of pipelines they derive, they
    are difficult for developers to debug. It is also challenging for machine learning
    experts to select an AutoML system that is well suited for a given problem. In
    this paper, we present the Pipeline Profiler, an interactive visualization tool
    that allows the exploration and comparison of the solution space of machine learning
    (ML) pipelines produced by AutoML systems. PipelineProfiler is integrated with
    Jupyter Notebook and can be combined with common data science tools to enable
    a rich set of analyses of the ML pipelines, providing users a better understanding
    of the algorithms that generated them as well as insights into how they can be
    improved. We demonstrate the utility of our tool through use cases where PipelineProfiler
    is used to better understand and improve a real-world AutoML system. Furthermore,
    we validate our approach by presenting a detailed analysis of a think-aloud experiment
    with six data scientists who develop and evaluate AutoML tools.
  githubURL: https://github.com/VIDA-NYU/PipelineVis
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pipelineprofiler
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/document/9222086
  releaseYear: 2021
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{noriInterpretMLUnifiedFramework2019,\n  title = {{{InterpretML}}:\
    \ {{A Unified Framework}} for {{Machine Learning Interpretability}}},\n  shorttitle\
    \ = {{{InterpretML}}},\n  author = {Nori, Harsha and Jenkins, Samuel and Koch,\
    \ Paul and Caruana, Rich},\n  year = {2019},\n  journal = {arXiv},\n  url = {http://arxiv.org/abs/1909.09223},\n\
    \  urldate = {2021-05-11}\n}\n"
  communication: ''
  description: 'InterpretML is an open-source Python package which exposes machine
    learning interpretability algorithms to practitioners and researchers. InterpretML
    exposes two types of interpretability - glassbox models, which are machine learning
    models designed for interpretability (ex: linear models, rule lists, generalized
    additive models), and blackbox explainability techniques for explaining existing
    systems (ex: Partial Dependence, LIME). The package enables practitioners to easily
    compare interpretability algorithms by exposing multiple methods under a unified
    API, and by having a built-in, extensible visualization platform. InterpretML
    also includes the first implementation of the Explainable Boosting Machine, a
    powerful, interpretable, glassbox model that can be as accurate as many blackbox
    models. The MIT licensed source code can be downloaded from this http URL.'
  githubURL: https://github.com/interpretml/interpret
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: interpretml
  otherURLs: []
  paperURL: https://arxiv.org/abs/1909.09223
  releaseYear: 2019
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{faustInteractiveVisualizationData2022,\n  title = {Interactive\
    \ {{Visualization}} for {{Data Science Scripts}}},\n  booktitle = {2022 {{IEEE\
    \ Visualization}} in {{Data Science}} ({{VDS}})},\n  author = {Faust, Rebecca\
    \ and Scheidegger, Carlos and Isaacs, Katherine and Bernstein, William Z. and\
    \ Sharp, Michael and North, Chris},\n  year = {2022},\n  doi = {10.1109/VDS57266.2022.00009},\n\
    \  url = {https://ieeexplore.ieee.org/document/9982307/},\n  urldate = {2023-04-04}\n\
    }\n"
  communication: ''
  description: "As the field of data science continues to grow, so does the need for\
    \ adequate tools to understand and debug data science scripts. Current debugging\
    \ practices fall short when applied to a data science setting, due to the exploratory\
    \ and iterative nature of analysis scripts. Additionally, computational notebooks,\
    \ the preferred scripting environment of many data scientists, present additional\
    \ challenges to understanding and debugging workflows, including the non-linear\
    \ execution of code snippets. This paper presents Anteater, a trace-based visual\
    \ debugging method for data science scripts. Anteater automatically traces and\
    \ visualizes execution data with minimal analyst input. The visualizations illustrate\
    \ execution and value behaviors that aid in understanding the results of analysis\
    \ scripts. To maximize the number of workflows supported, we present prototype\
    \ implementations in both Python and Jupyter. Last, to demonstrate Anteater\u2019\
    s support for analysis understanding tasks, we provide two usage scenarios on\
    \ real world analysis scripts."
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: anteater
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/abstract/document/9982307
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{angrimanInteractiveVisualizationProtein2022,\n  title =\
    \ {Interactive {{Visualization}} of {{Protein RINs}} Using {{NetworKit}} in the\
    \ {{Cloud}}},\n  booktitle = {2022 {{IEEE International Parallel}} and {{Distributed\
    \ Processing Symposium Workshops}} ({{IPDPSW}})},\n  author = {Angriman, Eugenio\
    \ and {Brandt-Tumescheit}, Fabian and Franke, Leon and {van der Grinten}, Alexander\
    \ and Meyerhenke, Henning},\n  year = {2022},\n  doi = {10.1109/IPDPSW55747.2022.00055},\n\
    \  url = {https://ieeexplore.ieee.org/document/9835218/},\n  urldate = {2023-04-04}\n\
    }\n"
  communication: ''
  description: Network analysis has been applied in diverse application domains. We
    consider an application from protein dynamics, specifically residue interaction
    networks (RINs). While numerous RIN visualization tools exist, there are no solutions
    that are both easily programmable and as fast as optimized network analysis toolkits.
    In this work, we use NetworKit - an established package for network analysis -
    to build a cloud-based environment that enables domain scientists to run their
    visualization and analysis workflows on large compute servers, without requiring
    extensive programming and/or system administration knowledge. To demonstrate the
    versatility of this approach, we use it to build a custom Jupyter-based widget
    for RIN visualization. In contrast to existing RIN visualization approaches, our
    widget can easily be customized through simple modifications of Python code, while
    both supporting a comprehensive feature set and providing near real-time speed.
    Due to its integration into Jupyter notebooks, our widget can easily interact
    with other popular packages of the Python ecosystem to build custom analysis pipelines
    (e.g., pipelines that feed RIN data into downstream machine learning tasks).
  githubURL: https://github.com/networkit/networkit
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: networkit
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9835218
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{xenopoulosCalibrateInteractiveAnalysis2023,\n  title = {Calibrate:\
    \ {{Interactive Analysis}} of {{Probabilistic Model Output}}},\n  shorttitle =\
    \ {Calibrate},\n  author = {Xenopoulos, Peter and Rulff, Joao and Nonato, Luis\
    \ Gustavo and Barr, Brian and Silva, Claudio},\n  year = {2023},\n  journal =\
    \ {IEEE Transactions on Visualization and Computer Graphics},\n  volume = {29},\n\
    \  doi = {10.1109/TVCG.2022.3209489},\n  url = {https://ieeexplore.ieee.org/document/9904444/},\n\
    \  urldate = {2023-04-04}\n}\n"
  communication: ''
  description: Analyzing classification model performance is a crucial task for machine
    learning practitioners. While practitioners often use count-based metrics derived
    from confusion matrices, like accuracy, many applications, such as weather prediction,
    sports betting, or patient risk prediction, rely on a classifier's predicted probabilities
    rather than predicted labels. In these instances, practitioners are concerned
    with producing a calibrated model, that is, one which outputs probabilities that
    reflect those of the true distribution. Model calibration is often analyzed visually,
    through static reliability diagrams, however, the traditional calibration visualization
    may suffer from a variety of drawbacks due to the strong aggregations it necessitates.
    Furthermore, count-based approaches are unable to sufficiently analyze model calibration.
    We present Calibrate, an interactive reliability diagram that addresses the aforementioned
    issues. Calibrate constructs a reliability diagram that is resistant to drawbacks
    in traditional approaches, and allows for interactive subgroup analysis and instance-level
    inspection. We demonstrate the utility of Calibrate through use cases on both
    real-world and synthetic data. We further validate Calibrate by presenting the
    results of a think-aloud experiment with data scientists who routinely analyze
    model calibration.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: calibrate
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/abstract/document/9904444?casa_token=OC_9nVrCO-gAAAAA:czP34_qgxQqP2rWqUzGSGUZ7WbW9BDVhwQ31wggwd7lvqfx3gGrvT6z-wtGfkTjBH23Q2_iOOw
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{drososWrexUnifiedProgrammingbyExample2020,\n  title = {Wrex:\
    \ {{A Unified Programming-by-Example Interaction}} for {{Synthesizing Readable\
    \ Code}} for {{Data Scientists}}},\n  shorttitle = {Wrex},\n  booktitle = {Proceedings\
    \ of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},\n\
    \  author = {Drosos, Ian and Barik, Titus and Guo, Philip J. and DeLine, Robert\
    \ and Gulwani, Sumit},\n  year = {2020},\n  doi = {10.1145/3313831.3376442},\n\
    \  url = {https://dl.acm.org/doi/10.1145/3313831.3376442},\n  urldate = {2023-04-04},\n\
    \  langid = {english}\n}\n"
  communication: ''
  description: Data wrangling is a difficult and time-consuming activity in computational
    notebooks, and existing wrangling tools do not fit the exploratory workflow for
    data scientists in these environments. We propose a unified interaction model
    based on programming-by-example that generates readable code for a variety of
    useful data transformations, implemented as a Jupyter notebook extension called
    Wrex. User study results demonstrate that data scientists are significantly more
    effective and efficient at data wrangling with Wrex over manual programming. Qualitative
    participant feedback indicates that Wrex was useful and reduced barriers in having
    to recall or look up the usage of various data transform functions. The synthesized
    code allowed data scientists to verify the intended data transformation, increased
    their trust and confidence in Wrex, and fit seamlessly within their cell-based
    notebook workflows. This work suggests that presenting readable code to professional
    data scientists is an indispensable component of offering data wrangling tools
    in notebooks.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: wrex
  otherURLs: []
  paperURL: https://dl.acm.org/doi/abs/10.1145/3313831.3376442
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{fujiwaraInteractiveDimensionalityReduction2022,\n  title = {Interactive\
    \ {{Dimensionality Reduction}} for {{Comparative Analysis}}},\n  author = {Fujiwara,\
    \ Takanori and Wei, Xinhai and Zhao, Jian and Ma, Kwan-Liu},\n  year = {2022},\n\
    \  journal = {IEEE Transactions on Visualization and Computer Graphics},\n  volume\
    \ = {28},\n  doi = {10.1109/TVCG.2021.3114807},\n  url = {https://ieeexplore.ieee.org/document/9555244/},\n\
    \  urldate = {2023-04-04}\n}\n"
  communication: ''
  description: Finding the similarities and differences between groups of datasets
    is a fundamental analysis task. For high-dimensional data, dimensionality reduction
    (DR) methods are often used to find the characteristics of each group. However,
    existing DR methods provide limited capability and flexibility for such comparative
    analysis as each method is designed only for a narrow analysis target, such as
    identifying factors that most differentiate groups. This paper presents an interactive
    DR framework where we integrate our new DR method, called ULCA (unified linear
    comparative analysis), with an interactive visual interface. ULCA unifies two
    DR schemes, discriminant analysis and contrastive learning, to support various
    comparative analysis tasks. To provide flexibility for comparative analysis, we
    develop an optimization algorithm that enables analysts to interactively refine
    ULCA results. Additionally, the interactive visualization interface facilitates
    interpretation and refinement of the ULCA results. We evaluate ULCA and the optimization
    algorithm to show their efficiency as well as present multiple case studies using
    real-world datasets to demonstrate the usefulness of this framework.
  githubURL: https://github.com/takanori-fujiwara/ulca
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: ulca
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/document/9555244
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{zhangMEGAnnoExploratoryLabeling2022,\n  title = {{{MEGAnno}}:\
    \ {{Exploratory Labeling}} for {{NLP}} in {{Computational Notebooks}}},\n  booktitle\
    \ = {Proceedings of the {{Fourth Workshop}} on {{Data Science}} with {{Human-in-the-Loop}}\
    \ ({{Language Advances}})},\n  author = {Zhang, Dan and Kim, Hannah and Li Chen,\
    \ Rafael and Kandogan, Eser and Hruschka, Estevam},\n  year = {2022},\n  url =\
    \ {https://aclanthology.org/2022.dash-1.1}\n}\n"
  communication: ''
  description: "We present MEGAnno, a novel exploratory annotation framework designed\
    \ for NLP researchers and practitioners. Unlike existing labeling tools that focus\
    \ on data labeling only, our framework aims to support a broader, iterative ML\
    \ workflow including data exploration and model development. With MEGAnno\u2019\
    s API, users can programmatically explore the data through sophisticated search\
    \ and automated suggestion functions and incrementally update task schema as their\
    \ project evolve. Combined with our widget, the users can interactively sort,\
    \ filter, and assign labels to multiple items simultaneously in the same notebook\
    \ where the rest of the NLP project resides. We demonstrate MEGAnno\u2019s flexible,\
    \ exploratory, efficient, and seamless labeling experience through a sentiment\
    \ analysis use case."
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: meganno
  otherURLs: []
  paperURL: https://aclanthology.org/2022.dash-1.1/
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{wangInteractivePlotManipulation2021,\n  title = {Interactive\
    \ {{Plot Manipulation}} Using {{Natural Language}}},\n  booktitle = {Proceedings\
    \ of the 2021 {{Conference}} of the {{North American Chapter}} of the {{Association}}\
    \ for {{Computational Linguistics}}: {{Human Language Technologies}}: {{Demonstrations}}},\n\
    \  author = {Wang, Yihan and Shao, Yutong and Nakashole, Ndapa},\n  year = {2021},\n\
    \  doi = {10.18653/v1/2021.naacl-demos.11},\n  url = {https://www.aclweb.org/anthology/2021.naacl-demos.11},\n\
    \  urldate = {2023-04-05},\n  langid = {english}\n}\n"
  communication: ''
  description: We present an interactive Plotting Agent, a system that enables users
    to directly manipulate plots using natural language instructions within an interactive
    programming environment. The Plotting Agent maps language to plot updates. We
    formulate this problem as a slot-based task-oriented dialog problem, which we
    tackle with a sequence-to-sequence model. This plotting model while accurate in
    most cases, still makes errors, therefore, the system allows a feedback mode,
    wherein the user is presented with a top-k list of plots, among which the user
    can pick the desired one. From this kind of feedback, we can then, in principle,
    continuously learn and improve the system. Given that plotting is widely used
    across data-driven fields, we believe our demonstration will be of interest to
    both practitioners such as data scientists broadly defined, and researchers interested
    in natural language interfaces.
  githubURL: https://github.com/Bawerlacher/Plotting_Agent
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: plotting-agent
  otherURLs: []
  paperURL: https://aclanthology.org/2021.naacl-demos.11/
  releaseYear: 2021
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{zhangVizProgIdentifyingMisunderstandings2023,\n  title =\
    \ {{{VizProg}}: {{Identifying Misunderstandings By Visualizing Students}}' {{Coding\
    \ Progress}}},\n  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human\
    \ Factors}} in {{Computing Systems}}},\n  author = {Zhang, Ashley and Chen, Yan\
    \ and Oney, Steve},\n  year = {2023},\n  langid = {english}\n}\n"
  communication: ''
  description: "Programming instructors often conduct in-class exercises to help them\
    \ identify students that are falling behind and surface students\u2019 misconceptions.\
    \ However, as we found in interviews with programming instructors, monitoring\
    \ students\u2019 progress during exercises is difficult, particularly for large\
    \ classes. We present VizProg, a system that allows instructors to monitor and\
    \ inspect students\u2019 coding progress in real-time during in-class exercises.\
    \ VizProg represents students\u2019 statuses as a 2D Euclidean spatial map that\
    \ encodes the students\u2019 problem-solving approaches and progress in real-time.\
    \ VizProg allows instructors to navigate the temporal and structural evolution\
    \ of students\u2019 code, understand relationships between code, and determine\
    \ when to provide feedback. A comparison experiment showed that VizProg helped\
    \ to identify more students\u2019 problems than a baseline system. VizProg also\
    \ provides richer and more comprehensive information for identifying important\
    \ student behavior. By managing students\u2019 activities at scale, this work\
    \ presents a new paradigm for improving the quality of live learning."
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: vizprog
  otherURLs: []
  paperURL: https://chensivan.github.io/papers/chi2023_vizprog.pdf
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{narechaniaNL4DVToolkitGenerating2021,\n  title = {{{NL4DV}}: {{A\
    \ Toolkit}} for {{Generating Analytic Specifications}} for {{Data Visualization}}\
    \ from {{Natural Language Queries}}},\n  shorttitle = {{{NL4DV}}},\n  author =\
    \ {Narechania, Arpit and Srinivasan, Arjun and Stasko, John},\n  year = {2021},\n\
    \  journal = {IEEE Transactions on Visualization and Computer Graphics},\n  volume\
    \ = {27},\n  doi = {10.1109/TVCG.2020.3030378},\n  url = {https://ieeexplore.ieee.org/document/9222342/},\n\
    \  urldate = {2023-04-06}\n}\n"
  communication: ''
  description: 'Natural language interfaces (NLls) have shown great promise for visual
    data analysis, allowing people to flexibly specify and interact with visualizations.
    However, developing visualization NLIs remains a challenging task, requiring low-level
    implementation of natural language processing (NLP) techniques as well as knowledge
    of visual analytic tasks and visualization design. We present NL4DV, a toolkit
    for natural language-driven data visualization. NL4DV is a Python package that
    takes as input a tabular dataset and a natural language query about that dataset.
    In response, the toolkit returns an analytic specification modeled as a JSON object
    containing data attributes, analytic tasks, and a list of Vega-Lite specifications
    relevant to the input query. In doing so, NL4DV aids visualization developers
    who may not have a background in NLP, enabling them to create new visualization
    NLIs or incorporate natural language input within their existing systems. We demonstrate
    NL4DV''s usage and capabilities through four examples: 1) rendering visualizations
    using natural language in a Jupyter notebook, 2) developing a NLI to specify and
    edit Vega-Lite charts, 3) recreating data ambiguity widgets from the DataTone
    system, and 4) incorporating speech input to create a multimodal visualization
    system.'
  githubURL: https://github.com/nl4dv/nl4dv
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: nl4dv
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/document/9222342
  releaseYear: 2021
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{robbinsGILPInteractiveTool2023,\n  title = {{{GILP}}: {{An\
    \ Interactive Tool}} for {{Visualizing}} the {{Simplex Algorithm}}},\n  shorttitle\
    \ = {{{GILP}}},\n  booktitle = {Proceedings of the 54th {{ACM Technical Symposium}}\
    \ on {{Computer Science Education V}}. 1},\n  author = {Robbins, Henry W. and\
    \ Gutekunst, Samuel C. and Shmoys, David B. and Williamson, David P.},\n  year\
    \ = {2023},\n  doi = {10.1145/3545945.3569815},\n  url = {https://dl.acm.org/doi/10.1145/3545945.3569815},\n\
    \  urldate = {2023-04-06},\n  langid = {english}\n}\n"
  communication: ''
  description: 'The Simplex algorithm for solving linear programs---one of Computing
    in Science & Engineering''s top 10 most influential algorithms of the 20th century---is
    an important topic in many algorithms courses. While the algorithm relies on intuitive
    geometric ideas, the computationally-involved mechanics of the algorithm can obfuscate
    a geometric understanding. In this paper, we present gilp, an easy-to-use Simplex
    algorithm visualization tool designed to connect the mechanical steps of the algorithm
    with their geometric interpretation. We provide an extensive library of example
    visualizations, and our tool allows instructors to quickly produce custom interactive
    HTML files for students to experiment with the algorithm (without requiring students
    to install anything!). The tool can also be used for interactive assignments in
    Jupyter notebooks, and has been incorporated into a forthcoming Data Science and
    Decision Making interactive textbook. In this paper, we first describe how the
    tool fits into the existing algorithm visualization literature: how it was designed
    to facilitate student engagement and instructor adoption, and how it substantially
    extends existing algorithm visualization tools for Simplex. We then describe the
    development and usage of the tool, and report feedback from its use in a course
    with roughly 100 students. Student feedback was overwhelmingly positive, with
    students finding the tool easy to use: it effectively helped them link the algebraic
    and geometrical views of the Simplex algorithm and understand its nuances. Finally,
    gilp is open-source, includes an extension to visualizing linear programming-based
    branch and bound, and is readily amenable to further extensions.'
  githubURL: https://github.com/engri-1101/gilp
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: gilp
  otherURLs: []
  paperURL: https://dl.acm.org/doi/10.1145/3545945.3569815
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{zhaoNotebookVRENaaVRE2022,\n  title = {Notebook-as-a-{{VRE}} ({{NaaVRE}}):\
    \ {{From}} Private Notebooks to a Collaborative Cloud Virtual Research Environment},\n\
    \  shorttitle = {Notebook-as-a-{{VRE}} ({{NaaVRE}})},\n  author = {Zhao, Zhiming\
    \ and Koulouzis, Spiros and Bianchi, Riccardo and Farshidi, Siamak and Shi, Zeshun\
    \ and Xin, Ruyue and Wang, Yuandou and Li, Na and Shi, Yifang and Timmermans,\
    \ Joris and Kissling, W. Daniel},\n  year = {2022},\n  journal = {Software: Practice\
    \ and Experience},\n  volume = {52},\n  doi = {10.1002/spe.3098},\n  url = {https://onlinelibrary.wiley.com/doi/10.1002/spe.3098},\n\
    \  urldate = {2023-04-06},\n  langid = {english}\n}\n"
  communication: ''
  description: Virtual Research Environments (VREs) provide user-centric support in
    the lifecycle of research activities, e.g., discovering and accessing research
    assets, or composing and executing application workflows. A typical VRE is often
    implemented as an integrated environment, which includes a catalog of research
    assets, a workflow management system, a data management framework, and tools for
    enabling collaboration among users. Notebook environments, such as Jupyter, allow
    researchers to rapidly prototype scientific code and share their experiments as
    online accessible notebooks. Jupyter can support several popular languages that
    are used by data scientists, such as Python, R, and Julia. However, such notebook
    environments do not have seamless support for running heavy computations on remote
    infrastructure or finding and accessing software code inside notebooks. This paper
    investigates the gap between a notebook environment and a VRE and proposes an
    embedded VRE solution for the Jupyter environment called Notebook-as-a-VRE (NaaVRE).
    The NaaVRE solution provides functional components via a component marketplace
    and allows users to create a customized VRE on top of the Jupyter environment.
    From the VRE, a user can search research assets (data, software, and algorithms),
    compose workflows, manage the lifecycle of an experiment, and share the results
    among users in the community. We demonstrate how such a solution can enhance a
    legacy workflow that uses Light Detection and Ranging (LiDAR) data from country-wide
    airborne laser scanning surveys for deriving geospatial data products of ecosystem
    structure at high resolution over broad spatial extents. This enables users to
    scale out the processing of multi-terabyte LiDAR point clouds for ecological applications
    to more data sources in a distributed cloud environment.
  githubURL: https://github.com/QCDIS/NaaVRE
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: naavre
  otherURLs: []
  paperURL: https://arxiv.org/abs/2111.12785
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{wangVizSeqVisualAnalysis2019,\n  title = {{{VizSeq}}: A\
    \ Visual Analysis Toolkit for Text Generation Tasks},\n  shorttitle = {{{VizSeq}}},\n\
    \  booktitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}}\
    \ in {{Natural Language Processing}} and the 9th {{International Joint Conference}}\
    \ on {{Natural Language Processing}} ({{EMNLP-IJCNLP}}): {{System Demonstrations}}},\n\
    \  author = {Wang, Changhan and Jain, Anirudh and Chen, Danlu and Gu, Jiatao},\n\
    \  year = {2019},\n  doi = {10.18653/v1/D19-3043},\n  url = {https://www.aclweb.org/anthology/D19-3043},\n\
    \  urldate = {2022-08-26},\n  langid = {english}\n}\n"
  communication: ''
  description: Automatic evaluation of text generation tasks (e.g. machine translation,
    text summarization, image captioning and video description) usually relies heavily
    on task-specific metrics, such as BLEU and ROUGE. They, however, are abstract
    numbers and are not perfectly aligned with human assessment. This suggests inspecting
    detailed examples as a complement to identify system error patterns. In this paper,
    we present VizSeq, a visual analysis toolkit for instance-level and corpus-level
    system evaluation on a wide variety of text generation tasks. It supports multimodal
    sources and multiple text references, providing visualization in Jupyter notebook
    or a web app interface. It can be used locally or deployed onto public servers
    for centralized data hosting and benchmarking. It covers most common n-gram based
    metrics accelerated with multiprocessing, and also provides latest embedding-based
    metrics such as BERTScore.
  githubURL: https://github.com/facebookresearch/vizseq
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: vizseq
  otherURLs: []
  paperURL: https://aclanthology.org/D19-3043/
  releaseYear: 2019
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{liArgoLiteOpenSource2020,\n  title = {Argo {{Lite}}: {{Open-Source\
    \ Interactive Graph Exploration}} and {{Visualization}} in {{Browsers}}},\n  shorttitle\
    \ = {Argo {{Lite}}},\n  booktitle = {{{CIKM}}},\n  author = {Li, Siwei and Zhou,\
    \ Zhiyan and Upadhayay, Anish and Shaikh, Omar and Freitas, Scott and Park, Haekyu\
    \ and Wang, Zijie J. and Routray, Susanta and Hull, Matthew and Chau, Duen Horng},\n\
    \  year = {2020},\n  doi = {10.1145/3340531.3412877},\n  url = {https://dl.acm.org/doi/10.1145/3340531.3412877},\n\
    \  urldate = {2022-09-01},\n  langid = {english}\n}\n"
  communication: ''
  description: Graph data have become increasingly common. Visualizing them helps
    people better understand relations among entities. Unfortunately, existing graph
    visualization tools are primarily designed for single-person desktop use, offering
    limited support for interactive web-based exploration and online collaborative
    analysis. To address these issues, we have developed Argo Lite, a new in-browser
    interactive graph exploration and visualization tool. Argo Lite enables users
    to publish and share interactive graph visualizations as URLs and embedded web
    widgets. Users can explore graphs incrementally by adding more related nodes,
    such as highly cited papers cited by or citing a paper of interest in a citation
    network. Argo Lite works across devices and platforms, leveraging WebGL for high-performance
    rendering. Argo Lite has been used by over 1,000 students at Georgia Tech's Data
    and Visual Analytics class. Argo Lite may serve as a valuable open-source tool
    for advancing multiple CIKM research areas, from data presentation, to interfaces
    for information systems and more.
  githubURL: https://github.com/poloclub/argo-graph-lite
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: argo-lite
  otherURLs: []
  paperURL: https://doi.org/10.1145/3340531.3412877
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{gurvichFireflyBrowserbasedInteractive2023,\n  title = {Firefly:\
    \ {{A Browser-based Interactive 3D Data Visualization Tool}} for {{Millions}}\
    \ of {{Data Points}}},\n  shorttitle = {Firefly},\n  author = {Gurvich, Alexander\
    \ B. and Geller, Aaron M.},\n  year = {2023},\n  journal = {The Astrophysical\
    \ Journal Supplement Series},\n  volume = {265},\n  doi = {10.3847/1538-4365/acb59f},\n\
    \  url = {https://iopscience.iop.org/article/10.3847/1538-4365/acb59f},\n  urldate\
    \ = {2023-04-06}\n}\n"
  communication: ''
  description: "We present Firefly, a new browser-based interactive tool for visualizing\
    \ 3D particle data sets. On a typical personal computer, Firefly can simultaneously\
    \ render and enable real-time interactions with \u227310 million particles, and\
    \ can interactively explore data sets with billions of particles using the included\
    \ custom-built octree render engine. Once created, viewing a Firefly visualization\
    \ requires no installation and is immediately usable in most modern internet browsers\
    \ simply by visiting a URL. As a result, a Firefly visualization works out-of-the-box\
    \ on most devices including smartphones and tablets. Firefly is primarily developed\
    \ for researchers to explore their own data, but can also be useful to communicate\
    \ results to researchers and/or collaborators and as an effective public outreach\
    \ tool. Every element of the user interface can be customized and disabled, enabling\
    \ easy adaptation of the same visualization for different audiences with little\
    \ additional effort. Creating a new Firefly visualization is simple with the provided\
    \ Python data preprocessor that translates input data to a Firefly-compatible\
    \ format and provides helpful methods for hosting instances of Firefly both locally\
    \ and on the internet. In addition to visualizing the positions of particles,\
    \ users can visualize vector fields (e.g., velocities) and also filter and color\
    \ points by scalar fields. We share three examples of Firefly applied to astronomical\
    \ data sets: (1) the FIRE cosmological zoom-in simulations, (2) the SDSS galaxy\
    \ catalog, and (3) Gaia Data Release 3. A gallery of additional interactive demos\
    \ is available at alexbgurvi.ch/Firefly."
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: firefly
  otherURLs: []
  paperURL: https://iopscience.iop.org/article/10.3847/1538-4365/acb59f
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{arayaJOVIALNotebookbasedAstronomical2018,\n  title = {{{JOVIAL}}:\
    \ {{Notebook-based}} Astronomical Data Analysis in the Cloud},\n  shorttitle =\
    \ {{{JOVIAL}}},\n  author = {Araya, M. and Osorio, M. and D{\\'i}az, M. and Ponce,\
    \ C. and Villanueva, M. and Valenzuela, C. and Solar, M.},\n  year = {2018},\n\
    \  journal = {Astronomy and Computing},\n  volume = {25},\n  doi = {10.1016/j.ascom.2018.09.001},\n\
    \  url = {https://linkinghub.elsevier.com/retrieve/pii/S2213133718300180},\n \
    \ urldate = {2023-04-06},\n  langid = {english}\n}\n"
  communication: ''
  description: Performing astronomical data analysis using only personal computers
    is becoming impractical for the very large datasets produced nowadays. As analysis
    is not a task that can be automatized to its full extent, the idea of moving processing
    where the data is located means also moving the whole scientific process towards
    the archives and data centers. Using Jupyter Notebooks as a remote service is
    a recent trend in data analysis that aims to deal with this problem, but harnessing
    the infrastructure to serve the astronomer without increasing the complexity of
    the service is a challenge. In this paper we present the architecture and features
    of JOVIAL, a Cloud service where astronomers can safely use Jupyter notebooks
    over a personal space designed for high-performance processing under the high-availability
    principle. We show that features existing only in specific packages can be adapted
    to run in the notebooks, and that algorithms can be adapted to run across the
    data center without necessarily redesigning them.
  githubURL: https://github.com/ChileanVirtualObservatory/smoothy
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: smoothy
  otherURLs: []
  paperURL: https://www.sciencedirect.com/science/article/pii/S2213133718300180?via%3Dihub
  releaseYear: 2018
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{palmeirojoaoDataShiftSupporting2022,\n  title = {Data+{{Shift}}:\
    \ {{Supporting Visual Investigation}} of {{Data Distribution Shifts}} by {{Data\
    \ Scientists}}},\n  shorttitle = {Data+{{Shift}}},\n  author = {Palmeiro, Jo{\\\
    ~a}o and Malveiro, Beatriz and Costa, Rita and Polido, David and Moreira, Ricardo\
    \ and Bizarro, Pedro},\n  year = {2022},\n  doi = {10.2312/EVS.20221097},\n  url\
    \ = {https://diglib.eg.org/handle/10.2312/evs20221097},\n  urldate = {2022-08-29}\n\
    }\n"
  communication: ''
  description: Machine learning on data streams is increasingly more present in multiple
    domains. However, there is often data distribution shift that can lead machine
    learning models to make incorrect decisions. While there are automatic methods
    to detect when drift is happening, human analysis, often by data scientists, is
    essential to diagnose the causes of the problem and adjust the system. We propose
    Data+Shift, a visual analytics tool to support data scientists in the task of
    investigating the underlying factors of shift in data features in the context
    of fraud detection. Design requirements were derived from interviews with data
    scientists. Data+Shift is integrated with JupyterLab and can be used alongside
    other data science tools. We validated our approach with a think-aloud experiment
    where a data scientist used the tool for a fraud detection use case.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: data+shift
  otherURLs: []
  paperURL: https://doi.org/10.2312/evs.20221097
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{breddelsInteractiveStatisticalVisualisation2016,\n  title = {Interactive\
    \ (Statistical) Visualisation and Exploration of a Billion Objects with Vaex},\n\
    \  author = {Breddels, M. A.},\n  year = {2016},\n  journal = {Proceedings of\
    \ the International Astronomical Union},\n  volume = {12},\n  doi = {10.1017/S1743921316012795},\n\
    \  url = {https://www.cambridge.org/core/product/identifier/S1743921316012795/type/journal_article},\n\
    \  urldate = {2023-04-06},\n  langid = {english}\n}\n"
  communication: ''
  description: With new catalogues arriving such as the Gaia DR1, containing more
    than a billion objects, new methods of handling and visualizing these data volumes
    are needed. We show that by calculating statistics on a regular (N-dimensional)
    grid, visualizations of a billion objects can be done within a second on a modern
    desktop computer. This is achieved using memory mapping of hdf5 files together
    with a simple binning algorithm, which are part of a Python library called vaex.
    This enables efficient exploration or large datasets interactively, making science
    exploration of large catalogues feasible. Vaex is a Python library and an application,
    which allows for interactive exploration and visualization. The motivation for
    developing vaex is the catalogue of the Gaia satellite, however, vaex can also
    be used on SPH or N-body simulations, any other (future) catalogues such as SDSS,
    Pan-STARRS, LSST, etc. or other tabular data. The homepage for vaex is http://vaex.astro.rug.nl.
  githubURL: https://github.com/vaexio/vaex
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: vaex
  otherURLs: []
  paperURL: https://doi.org/10.1017/S1743921316012795
  releaseYear: 2016
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{sbailoNOMADArtificialIntelligenceToolkit2022,\n  title = {The\
    \ {{NOMAD Artificial-Intelligence Toolkit}}: Turning Materials-Science Data into\
    \ Knowledge and Understanding},\n  shorttitle = {The {{NOMAD Artificial-Intelligence\
    \ Toolkit}}},\n  author = {Sbail{\\`o}, Luigi and Fekete, {\\'A}d{\\'a}m and Ghiringhelli,\
    \ Luca M. and Scheffler, Matthias},\n  year = {2022},\n  journal = {npj Computational\
    \ Materials},\n  volume = {8},\n  doi = {10.1038/s41524-022-00935-z},\n  url =\
    \ {https://www.nature.com/articles/s41524-022-00935-z},\n  urldate = {2023-04-06},\n\
    \  langid = {english}\n}\n"
  communication: ''
  description: "We present the Novel-Materials-Discovery (NOMAD) Artificial-Intelligence\
    \ (AI) Toolkit, a web-browser-based infrastructure for the interactive AI-based\
    \ analysis of materials-science findable, accessible, interoperable, and reusable\
    \ (FAIR) data. The AI Toolkit readily operates on the FAIR data stored in the\
    \ central server of the NOMAD Archive, the largest database of materials-science\
    \ data worldwide, as well as locally stored, users\u2019 owned data. The NOMAD\
    \ Oasis, a local, stand-alone server can be also used to run the AI Toolkit. By\
    \ using Jupyter notebooks that run in a web-browser, the NOMAD data can be queried\
    \ and accessed; data mining, machine learning, and other AI techniques can be\
    \ then applied to analyze them. This infrastructure brings the concept of reproducibility\
    \ in materials science to the next level, by allowing researchers to share not\
    \ only the data contributing to their scientific publications, but also all the\
    \ developed methods and analytics tools. Besides reproducing published results,\
    \ users of the NOMAD AI toolkit can modify the Jupyter notebooks toward their\
    \ own research work."
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: nomad
  otherURLs: []
  paperURL: https://www.nature.com/articles/s41524-022-00935-z
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{dasCACTUSDetectingResolving2021,\n  title = {{{CACTUS}}: {{Detecting}}\
    \ and {{Resolving Conflicts}} in {{Objective Functions}}},\n  shorttitle = {{{CACTUS}}},\n\
    \  author = {Das, Subhajit and Endert, Alex},\n  year = {2021},\n  url = {http://arxiv.org/abs/2103.07805},\n\
    \  urldate = {2023-04-06},\n  archiveprefix = {arxiv},\n  journal = {2103.07805}\n\
    }\n"
  communication: ''
  description: 'Machine learning (ML) models are constructed by expert ML practitioners
    using various coding languages, in which they tune and select models hyperparameters
    and learning algorithms for a given problem domain. They also carefully design
    an objective function or loss function (often with multiple objectives) that captures
    the desired output for a given ML task such as classification, regression, etc.
    In multi-objective optimization, conflicting objectives and constraints is a major
    area of concern. In such problems, several competing objectives are seen for which
    no single optimal solution is found that satisfies all desired objectives simultaneously.
    In the past VA systems have allowed users to interactively construct objective
    functions for a classifier. In this paper, we extend this line of work by prototyping
    a technique to visualize multi-objective objective functions either defined in
    a Jupyter notebook or defined using an interactive visual interface to help users
    to: (1) perceive and interpret complex mathematical terms in it and (2) detect
    and resolve conflicting objectives. Visualization of the objective function enlightens
    potentially conflicting objectives that obstructs selecting correct solution(s)
    for the desired ML task or goal. We also present an enumeration of potential conflicts
    in objective specification in multi-objective objective functions for classifier
    selection. Furthermore, we demonstrate our approach in a VA system that helps
    users in specifying meaningful objective functions to a classifier by detecting
    and resolving conflicting objectives and constraints. Through a within-subject
    quantitative and qualitative user study, we present results showing that our technique
    helps users interactively specify meaningful objective functions by resolving
    potential conflicts for a classification task.'
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: cactus
  otherURLs: []
  paperURL: https://arxiv.org/abs/2103.07805
  releaseYear: 2021
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{sohnsAttributebasedExplanationNonLinear2022,\n  title = {Attribute-Based\
    \ {{Explanation}} of {{Non-Linear Embeddings}} of {{High-Dimensional Data}}},\n\
    \  author = {Sohns, Jan-Tobias and Schmitt, Michaela and Jirasek, Fabian and Hasse,\
    \ Hans and Leitte, Heike},\n  year = {2022},\n  journal = {IEEE Transactions on\
    \ Visualization and Computer Graphics},\n  volume = {28},\n  doi = {10.1109/TVCG.2021.3114870},\n\
    \  url = {https://ieeexplore.ieee.org/document/9552929/},\n  urldate = {2023-04-06}\n\
    }\n"
  communication: ''
  description: Embeddings of high-dimensional data are widely used to explore data,
    to verify analysis results, and to communicate information. Their explanation,
    in particular with respect to the input attributes, is often difficult. With linear
    projects like PCA the axes can still be annotated meaningfully. With non-linear
    projections this is no longer possible and alternative strategies such as attribute-based
    color coding are required. In this paper, we review existing augmentation techniques
    and discuss their limitations. We present the Non-Linear Embeddings Surveyor (NoLiES)
    that combines a novel augmentation strategy for projected data (rangesets) with
    interactive analysis in a small multiples setting. Rangesets use a set-based visualization
    approach for binned attribute values that enable the user to quickly observe structure
    and detect outliers. We detail the link between algebraic topology and rangesets
    and demonstrate the utility of NoLiES in case studies with various challenges
    (complex attribute value distribution, many attributes, many data points) and
    a real-world application to understand latent features of matrix completion in
    thermodynamics.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: nolies
  otherURLs: []
  paperURL: https://arxiv.org/abs/2108.08706
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{herwigCyberhubsVirtualResearch2018,\n  title = {Cyberhubs: {{Virtual\
    \ Research Environments}} for {{Astronomy}}},\n  shorttitle = {Cyberhubs},\n \
    \ author = {Herwig, Falk and Andrassy, Robert and Annau, Nic and Clarkson, Ondrea\
    \ and C{\\^o}t{\\'e}, Benoit and D'Sa, Aaron and Jones, Sam and Moa, Belaid and\
    \ O'Connell, Jericho and Porter, David and Ritter, Christian and Woodward, Paul},\n\
    \  year = {2018},\n  journal = {The Astrophysical Journal Supplement Series},\n\
    \  volume = {236},\n  doi = {10.3847/1538-4365/aab777},\n  url = {https://iopscience.iop.org/article/10.3847/1538-4365/aab777},\n\
    \  urldate = {2023-04-06}\n}\n"
  communication: ''
  description: Collaborations in astronomy and astrophysics are faced with numerous
    cyber-infrastructure challenges, such as large data sets, the need to combine
    heterogeneous data sets, and the challenge to effectively collaborate on those
    large, heterogeneous data sets with significant processing requirements and complex
    science software tools. The cyberhubs system is an easy-to-deploy package for
    small- to medium-sized collaborations based on the Jupyter and Docker technology,
    which allows web-browser-enabled, remote, interactive analytic access to shared
    data. It offers an initial step to address these challenges. The features and
    deployment steps of the system are described, as well as the requirements collection
    through an account of the different approaches to data structuring, handling,
    and available analytic tools for the NuGrid and PPMstar collaborations. NuGrid
    is an international collaboration that creates stellar evolution and explosion
    physics and nucleosynthesis simulation data. The PPMstar collaboration performs
    large-scale 3D stellar hydrodynamics simulations of interior convection in the
    late phases of stellar evolution. Examples of science that is currently performed
    on cyberhubs, in the areas of 3D stellar hydrodynamic simulations, stellar evolution
    and nucleosynthesis, and Galactic chemical evolution, are presented.
  githubURL: https://github.com/cyberlaboratories/cyberhubs
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: cyberhubs
  otherURLs: []
  paperURL: https://iopscience.iop.org/article/10.3847/1538-4365/aab777
  releaseYear: 2018
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{veranomerinoBacataNotebooksDSLs2020,\n  title = {Bacat\\'a: {{Notebooks}}\
    \ for {{DSLs}}, {{Almost}} for {{Free}}},\n  shorttitle = {Bacat\\'a},\n  author\
    \ = {Verano Merino, Mauricio and Vinju, Jurgen and {van der Storm}, Tijs},\n \
    \ year = {2020},\n  journal = {The Art, Science, and Engineering of Programming},\n\
    \  volume = {4},\n  doi = {10.22152/programming-journal.org/2020/4/11},\n  url\
    \ = {http://programming-journal.org/2020/4/11},\n  urldate = {2023-04-06},\n \
    \ langid = {english}\n}\n"
  communication: ''
  description: "Context: Computational notebooks are a contemporary style of literate\
    \ programming, in which users can communicate and transfer knowledge by interleaving\
    \ executable code, output, and prose in a single rich document. A Domain-Specific\
    \ Language (DSL) is an artificial software language tailored for a particular\
    \ application domain. Usually, DSL users are domain experts that may not have\
    \ a software engineering background. As a consequence, they might not be familiar\
    \ with Integrated Development Environments (IDEs). Thus, the development of tools\
    \ that offer different interfaces for interacting with a DSL is relevant. Inquiry:\
    \ However, resources available to DSL designers are limited. We would like to\
    \ leverage tools used to interact with general purpose languages in the context\
    \ of DSLs. Computational notebooks are an example of such tools. Then, our main\
    \ question is: What is an efficient and effective method of designing and implementing\
    \ notebook interfaces for DSLs? By addressing this question we might be able to\
    \ speed up the development of DSL tools, and ease the interaction between end-users\
    \ and DSLs. Approach: In this paper, we present Bacat\xE1, a mechanism for generating\
    \ notebook interfaces for DSLs in a language parametric fashion. We designed this\
    \ mechanism in a way in which language engineers can reuse as many language components\
    \ (e.g., language processors, type checkers, code generators) as possible. Knowledge:\
    \ Our results show that notebook interfaces generated by Bacat\xE1 can be automatically\
    \ generated with little manual configuration. There are few considerations and\
    \ caveats that should be addressed by language engineers that rely on language\
    \ design aspects. The creation of a notebook for a DSL with Bacat\xE1 becomes\
    \ a matter of writing the code that wires existing language components in the\
    \ Rascal language workbench with the Jupyter platform. Grounding: We evaluate\
    \ Bacat\xE1 by generating functional computational notebook interfaces for three\
    \ different non-trivial DSLs, namely: a small subset of Halide (a DSL for digital\
    \ image processing), SweeterJS (an extended version of JavaScript), and QL (a\
    \ DSL for questionnaires). Additionally, it is relevant to generate notebook implementations\
    \ rather than implementing them manually. We measured and compared the number\
    \ of Source Lines of Code (SLOCs) that we reused from existing implementations\
    \ of those languages. Importance: The adoption of notebooks by novice-programmers\
    \ and end-users has made them very popular in several domains such as exploratory\
    \ programming, data science, data journalism, and machine learning. Why are they\
    \ popular? In (data) science, it is essential to make results reproducible as\
    \ well as understandable. However, notebooks are only available for GPLs. This\
    \ paper opens up the notebook metaphor for DSLs to improve the end-user experience\
    \ when interacting with code and to increase DSLs adoption."
  githubURL: https://github.com/cwi-swat/bacata
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: bacata
  otherURLs: []
  paperURL: https://programming-journal.org/2020/4/11/
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{furmanovaTaggleCombiningOverview2020,\n  title = {Taggle: {{Combining}}\
    \ Overview and Details in Tabular Data Visualizations},\n  shorttitle = {Taggle},\n\
    \  author = {Furmanova, Katarina and Gratzl, Samuel and Stitz, Holger and Zichner,\
    \ Thomas and Jaresova, Miroslava and Lex, Alexander and Streit, Marc},\n  year\
    \ = {2020},\n  journal = {Information Visualization},\n  volume = {19},\n  doi\
    \ = {10.1177/1473871619878085},\n  url = {http://journals.sagepub.com/doi/10.1177/1473871619878085},\n\
    \  urldate = {2023-04-06},\n  langid = {english}\n}\n"
  communication: ''
  description: Most tabular data visualization techniques focus on overviews, yet
    many practical analysis tasks are concerned with investigating individual items
    of interest. At the same time, relating an item to the rest of a potentially large
    table is important. In this work we present Taggle, a tabular visualization technique
    for exploring and presenting large and complex tables. Taggle takes an item-centric,
    spreadsheet-like approach, visualizing each row in the source data individually
    using visual encodings for the cells. At the same time, Taggle introduces data-driven
    aggregation of data subsets. The aggregation strategy is complemented by interaction
    methods tailored to answer specific analysis questions, such as sorting based
    on multiple columns and rich data selection and filtering capabilities. We demonstrate
    Taggle using a case study conducted by a domain expert on complex genomics data
    analysis for the purpose of drug discovery.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: taggle
  otherURLs: []
  paperURL: https://arxiv.org/abs/1712.05944
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{kerzelMLProvLabProvenanceManagement2023,\n  title = {{{MLProvLab}}:\
    \ {{Provenance Management}} for {{Data Science Notebooks}}},\n  shorttitle = {{{MLProvLab}}},\n\
    \  author = {Kerzel, Dominik and {K{\\\"o}nig-Ries}, Birgitta and Sheeba, Samuel},\n\
    \  year = {2023},\n  doi = {10.18420/BTW2023-66},\n  url = {http://dl.gi.de/handle/20.500.12116/40375},\n\
    \  urldate = {2023-04-06},\n  langid = {english}\n}\n"
  communication: ''
  description: Computational notebooks are a form of computational narrative fostering
    reproducibility. They provide an interactive computing environment where users
    can run and modify code and repeat the exploration, providing an iterative communication
    between data scientists and code. While the ability to execute notebooks non-linearly
    benefits data scientists for exploration, the drawback is that it is possible
    to lose control over the datasets, variables, and methods defined in the notebook
    and their dependencies. Thus, in this process of user interaction and exploration,
    there can be a loss of execution history information. To prevent this, a possibility
    is needed to maintain provenance information. Provenance plays a significant role
    in data science, especially in facilitating the reproducibility of results. To
    this end, we developed a provenance management tool to help data scientists track,
    capture, compare, and visualize provenance information in notebook code environments.
    We conducted an evaluation with data scientists, where participants were asked
    to find specific provenance information from the execution history of a machine
    learning Jupyter notebook. The results from the performance and user evaluation
    show promising aspects of provenance management features of the tool. The resulting
    system, MLProvLab, is available as an open-source extension for JupyterLab.
  githubURL: https://github.com/fusion-jena/MLProvLab
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: mlprovlab
  otherURLs: []
  paperURL: https://dl.gi.de/bitstream/handle/20.500.12116/40375/C3-06.pdf?sequence=1&isAllowed=y
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{lamModelSketchingCentering2023,\n  title = {Model {{Sketching}}:\
    \ {{Centering Concepts}} in {{Early-Stage Machine Learning Model Design}}},\n\
    \  shorttitle = {Model {{Sketching}}},\n  author = {Lam, Michelle S. and Ma, Zixian\
    \ and Li, Anne and Freitas, Izequiel and Wang, Dakuo and Landay, James A. and\
    \ Bernstein, Michael S.},\n  year = {2023},\n  doi = {10.1145/3544548.3581290},\n\
    \  url = {http://arxiv.org/abs/2303.02884},\n  urldate = {2023-04-06},\n  archiveprefix\
    \ = {arxiv},\n  journal = {2303.02884}\n}\n"
  communication: ''
  description: "Machine learning practitioners often end up tunneling on low-level\
    \ technical details like model architectures and performance metrics. Could early\
    \ model development instead focus on high-level questions of which factors a model\
    \ ought to pay attention to? Inspired by the practice of sketching in design,\
    \ which distills ideas to their minimal representation, we introduce model sketching:\
    \ a technical framework for iteratively and rapidly authoring functional approximations\
    \ of a machine learning model's decision-making logic. Model sketching refocuses\
    \ practitioner attention on composing high-level, human-understandable concepts\
    \ that the model is expected to reason over (e.g., profanity, racism, or sarcasm\
    \ in a content moderation task) using zero-shot concept instantiation. In an evaluation\
    \ with 17 ML practitioners, model sketching reframed thinking from implementation\
    \ to higher-level exploration, prompted iteration on a broader range of model\
    \ designs, and helped identify gaps in the problem formulation\u2014all in a fraction\
    \ of the time ordinarily required to build a model."
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: modelsketchbook
  otherURLs: []
  paperURL: https://arxiv.org/abs/2303.02884
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{liNotableOntheflyAssistant2023,\n  title = {Notable: {{On-the-fly\
    \ Assistant}} for {{Data Storytelling}} in {{Computational Notebooks}}},\n  shorttitle\
    \ = {Notable},\n  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human\
    \ Factors}} in {{Computing Systems}}},\n  author = {Li, Haotian and Ying, Lu and\
    \ Zhang, Haidong and Wu, Yingcai and Qu, Huamin and Wang, Yun},\n  year = {2023},\n\
    \  doi = {10.1145/3544548.3580965},\n  url = {https://dl.acm.org/doi/10.1145/3544548.3580965},\n\
    \  urldate = {2023-04-24},\n  langid = {english}\n}\n"
  communication: ''
  description: Computational notebooks are widely used for data analysis. Their interleaved
    displays of code and execution results (e.g., visualizations) are welcomed since
    they enable iterative analysis and preserve the exploration process. However,
    the communication of data findings remains challenging in computational notebooks.
    Users have to carefully identify useful findings from useless ones, document them
    with texts and visual embellishments, and then organize them in different tools.
    Such workflow greatly increases their workload, according to our interviews with
    practitioners. To address the challenge, we designed Notable to offer on-the-fly
    assistance for data storytelling in computational notebooks. It provides intelligent
    support to minimize the work of documenting and organizing data findings and diminishes
    the cost of switching between data exploration and storytelling. To evaluate Notable,
    we conducted a user study with 12 data workers. The feedback from user study participants
    verifies its effectiveness and usability.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: notable
  otherURLs: []
  paperURL: https://arxiv.org/abs/2303.04059
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{wangSlide4NCreatingPresentation2023,\n  title = {{{Slide4N}}:\
    \ {{Creating Presentation Slides}} from {{Computational Notebooks}} with {{Human-AI\
    \ Collaboration}}},\n  booktitle = {Proceedings of the 2023 {{CHI Conference}}\
    \ on {{Human Factors}} in {{Computing Systems}}},\n  author = {Wang, Fengjie and\
    \ Liu, Xuye and Liu, Oujing and Neshati, Ali and Ma, Tengfei and Zhu, Min and\
    \ Zhao, Jian},\n  year = {2023},\n  langid = {english}\n}\n"
  communication: ''
  description: Data scientists often have to use other presentation tools (e.g., Microsoft
    PowerPoint) to create slides to communicate their analysis obtained using computational
    notebooks. Much tedious and repetitive work is needed to transfer the routines
    of notebooks (e.g., code, plots) to the presentable contents on slides (e.g.,
    bullet points, figures). We propose a human-AI collaborative approach and operationalize
    it within Slide4N, an interactive AI assistant for data scientists to create slides
    from computational notebooks. Slide4N leverages advanced natural language processing
    techniques to distill key information from user-selected notebook cells and then
    renders them in appropriate slide layouts. The tool also provides intuitive interactions
    that allow further refinement and customization of the generated slides. We evaluated
    Slide4N with a two-part user study, where participants appreciated this human-AI
    collaborative approach compared to fully-manual or fully-automatic methods. The
    results also indicate the usefulness and effectiveness of Slide4N in slide creation
    tasks from notebooks.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: slide4n
  otherURLs: []
  paperURL: https://www.jeffjianzhao.com/papers/slide4n.pdf
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{bavishiVizSmithAutomatedVisualization2021,\n  title = {{{VizSmith}}:\
    \ {{Automated Visualization Synthesis}} by {{Mining Data-Science Notebooks}}},\n\
    \  shorttitle = {{{VizSmith}}},\n  booktitle = {2021 36th {{IEEE}}/{{ACM International\
    \ Conference}} on {{Automated Software Engineering}} ({{ASE}})},\n  author = {Bavishi,\
    \ Rohan and Laddad, Shadaj and Yoshida, Hiroaki and Prasad, Mukul R. and Sen,\
    \ Koushik},\n  year = {2021},\n  doi = {10.1109/ASE51524.2021.9678696},\n  url\
    \ = {https://ieeexplore.ieee.org/document/9678696/},\n  urldate = {2023-04-13}\n\
    }\n"
  communication: ''
  description: Visualizations are widely used to communicate findings and make data-driven
    decisions. Unfortunately creating bespoke and reproducible visualizations requires
    the use of procedural tools such as matplotlib. These tools present a steep learning
    curve as their documentation often lacks sufficient usage examples to help beginners
    get started or accomplish a specific task. Forums such as StackOverflow have long
    helped developers search for code online and adapt it for their use. However,
    developers still have to sift through search results and understand the code before
    adapting it for their use.We built a tool called VizSmith which enables code reuse
    for visualizations by mining visualization code from Kaggle notebooks and creating
    a database of 7176 reusable Python functions. Given a dataset, columns to visualize
    and a text query from the user, VizSmith searches this database for appropriate
    functions, runs them and displays the generated visualizations to the user. At
    the core of VizSmith is a novel metamorphic testing based approach to automatically
    assess the reusability of functions, which improves end-to-end synthesis performance
    by 10% and cuts the number of execution failures by 50%.
  githubURL: https://github.com/rbavishi/vizsmith-demo
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: vizsmith
  otherURLs: []
  paperURL: https://ieeexplore.ieee.org/document/9678696
  releaseYear: 2021
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{eppersonLeveragingAnalysisHistory2022,\n  title = {Leveraging\
    \ {{Analysis History}} for {{Improved In Situ Visualization Recommendation}}},\n\
    \  author = {Epperson, Will and Jung-Lin Lee, Doris and Wang, Leijie and Agarwal,\
    \ Kunal and Parameswaran, Aditya G. and Moritz, Dominik and Perer, Adam},\n  year\
    \ = {2022},\n  journal = {Computer Graphics Forum},\n  volume = {41},\n  doi =\
    \ {10.1111/cgf.14529},\n  url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.14529},\n\
    \  urldate = {2023-04-13},\n  langid = {english}\n}\n"
  communication: ''
  description: "Existing visualization recommendation systems commonly rely on a single\
    \ snapshot of a dataset to suggest visualizations to users. However, exploratory\
    \ data analysis involves a series of related interactions with a dataset over\
    \ time rather than one-off analytical steps. We present Solas, a tool that tracks\
    \ the history of a user\u2019s data analysis, models their interest in each column,\
    \ and uses this information to provide visualization recommendations, all within\
    \ the user\u2019s native analytical environment. Recommending with analysis history\
    \ improves visualizations in three primary ways: task-specific visualizations\
    \ use the provenance of data to provide sensible encodings for common analysis\
    \ functions, aggregated history is used to rank visualizations by our model of\
    \ a user\u2019s interest in each column, and column data types are inferred based\
    \ on applied operations. We present a usage scenario and a user evaluation demonstrating\
    \ how leveraging analysis history improves in situ visualization recommendations\
    \ on real-world analysis tasks."
  githubURL: https://github.com/cmudig/solas
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: solas
  otherURLs: []
  paperURL: https://willepperson.com/papers/Solas_EuroVis22.pdf
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{guoCausalvisVisualizationsCausal2023,\n  title = {Causalvis:\
    \ {{Visualizations}} for {{Causal Inference}}},\n  booktitle = {Proceedings of\
    \ the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},\n\
    \  author = {Guo, Grace and Karavani, Ehud and Endert, Alex and Kwon, Bum Chul},\n\
    \  year = {2023}\n}\n"
  communication: ''
  description: Causal inference is a statistical paradigm for quantifying causal effects
    using observational data. It is a complex process, requiring multiple steps, iterations,
    and collaborations with domain experts. Analysts often rely on visualizations
    to evaluate the accuracy of each step. However, existing visualization toolkits
    are not designed to support the entire causal inference process within computational
    environments familiar to analysts. In this paper, we address this gap with Causalvis,
    a Python visualization package for causal inference. Working closely with causal
    inference experts, we adopted an iterative design process to develop four interactive
    visualization modules to support causal inference analysis tasks. The modules
    are then presented back to the experts for feedback and evaluation. We found that
    Causalvis effectively supported the iterative causal inference process. We discuss
    the implications of our findings for designing visualizations for causal inference,
    particularly for tasks of communication and collaboration.
  githubURL: https://github.com/causalvis/causalvis
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: causalvis
  otherURLs: []
  paperURL: https://arxiv.org/abs/2303.00617
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@article{wexlerWhatIfToolInteractive2019,\n  title = {The {{What-If Tool}}:\
    \ {{Interactive Probing}} of {{Machine Learning Models}}},\n  shorttitle = {The\
    \ {{What-If Tool}}},\n  author = {Wexler, James and Pushkarna, Mahima and Bolukbasi,\
    \ Tolga and Wattenberg, Martin and Viegas, Fernanda and Wilson, Jimbo},\n  year\
    \ = {2019},\n  journal = {IEEE TVCG},\n  volume = {26},\n  doi = {10.1109/TVCG.2019.2934619},\n\
    \  url = {https://ieeexplore.ieee.org/document/8807255/},\n  urldate = {2021-06-21}\n\
    }\n"
  communication: ''
  description: A key challenge in developing and deploying Machine Learning (ML) systems
    is understanding their performance across a wide range of inputs. To address this
    challenge, we created the What-If Tool, an open-source application that allows
    practitioners to probe, visualize, and analyze ML systems, with minimal coding.
    The What-If Tool lets practitioners test performance in hypothetical situations,
    analyze the importance of different data features, and visualize model behavior
    across multiple models and subsets of input data. It also lets practitioners measure
    systems according to multiple ML fairness metrics. We describe the design of the
    tool, and report on real-life usage at different organizations.
  githubURL: https://github.com/PAIR-code/what-if-tool
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: what-if-tool
  otherURLs: []
  paperURL: https://www.computer.org/csdl/journal/tg/2020/01/08807255/1cG6piAXFwQ
  releaseYear: 2019
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{tenneyLanguageInterpretabilityTool2020,\n  title = {The\
    \ Language Interpretability Tool: {{Extensible}}, Interactive Visualizations and\
    \ Analysis for {{NLP}} Models},\n  booktitle = {{{EMNLP Demo}}},\n  author = {Tenney,\
    \ Ian and Wexler, James and Bastings, Jasmijn and Bolukbasi, Tolga and Coenen,\
    \ Andy and Gehrmann, Sebastian and Jiang, Ellen and Pushkarna, Mahima and Radebaugh,\
    \ Carey and Reif, Emily and Yuan, Ann},\n  year = {2020},\n  doi = {10.18653/v1/2020.emnlp-demos.15},\n\
    \  url = {https://www.aclweb.org/anthology/2020.emnlp-demos.15}\n}\n"
  communication: ''
  description: "We present the Language Interpretability Tool (LIT), an open-source\
    \ platform for visualization and understanding of NLP models. We focus on core\
    \ questions about model behavior: Why did my model make this prediction? When\
    \ does it perform poorly? What happens under a controlled change in the input?\
    \ LIT integrates local explanations, aggregate analysis, and counterfactual generation\
    \ into a streamlined, browser-based interface to enable rapid exploration and\
    \ error analysis. We include case studies for a diverse set of workflows, including\
    \ exploring counterfactuals for sentiment analysis, measuring gender bias in coreference\
    \ systems, and exploring local behavior in text generation. LIT supports a wide\
    \ range of models\u2014including classification, seq2seq, and structured prediction\u2014\
    \ and is highly extensible through a declarative, framework-agnostic API. LIT\
    \ is under active development, with code and full documentation available at https://github.com/pair-code/lit."
  githubURL: https://github.com/PAIR-code/lit
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: lit-tool
  otherURLs: []
  paperURL: https://aclanthology.org/2020.emnlp-demos.15.pdf
  releaseYear: 2020
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{jainJigsawLargeLanguage2022,\n  title = {Jigsaw: Large Language\
    \ Models Meet Program Synthesis},\n  shorttitle = {Jigsaw},\n  booktitle = {Proceedings\
    \ of the 44th {{International Conference}} on {{Software Engineering}}},\n  author\
    \ = {Jain, Naman and Vaidyanath, Skanda and Iyer, Arun and Natarajan, Nagarajan\
    \ and Parthasarathy, Suresh and Rajamani, Sriram and Sharma, Rahul},\n  year =\
    \ {2022},\n  doi = {10.1145/3510003.3510203},\n  url = {https://dl.acm.org/doi/10.1145/3510003.3510203},\n\
    \  urldate = {2023-04-20},\n  langid = {english}\n}\n"
  communication: ''
  description: Large pre-trained language models such as GPT-3, Codex, and Google's
    language model are now capable of generating code from natural language specifications
    of programmer intent. We view these developments with a mixture of optimism and
    caution. On the optimistic side, such large language models have the potential
    to improve productivity by providing an automated AI pair programmer for every
    programmer in the world. On the cautionary side, since these large language models
    do not understand program semantics, they offer no guarantees about quality of
    the suggested code. In this paper, we present an approach to augment these large
    language models with post-processing steps based on program analysis and synthesis
    techniques, that understand the syntax and semantics of programs. Further, we
    show that such techniques can make use of user feedback and improve with usage.
    We present our experiences from building and evaluating such a tool jigsaw, targeted
    at synthesizing code for using Python Pandas API using multi-modal inputs. Our
    experience suggests that as these large language models evolve for synthesizing
    code from intent, jigsaw has an important role to play in improving the accuracy
    of the systems.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: jigsaw
  otherURLs: []
  paperURL: https://arxiv.org/abs/2112.02969
  releaseYear: 2022
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{bhatAspirationsPracticeModel2023,\n  title = {Aspirations\
    \ and {{Practice}} of {{Model Documentation}}: {{Moving}} the {{Needle}} with\
    \ {{Nudging}} and {{Traceability}}},\n  shorttitle = {Aspirations and {{Practice}}\
    \ of {{Model Documentation}}},\n  booktitle = {Proceedings of the 2023 {{CHI Conference}}\
    \ on {{Human Factors}} in {{Computing Systems}}},\n  author = {Bhat, Avinash and\
    \ Coursey, Austin and Hu, Grace and Li, Sixian and Nahar, Nadia and Zhou, Shurui\
    \ and K{\\\"a}stner, Christian and Guo, Jin L. C.},\n  year = {2023},\n  doi =\
    \ {10.1145/3544548.3581518},\n  url = {http://arxiv.org/abs/2204.06425},\n  urldate\
    \ = {2023-04-20},\n  archiveprefix = {arxiv},\n  journal = {2204.06425}\n}\n"
  communication: ''
  description: The documentation practice for machine-learned (ML) models often falls
    short of established practices for traditional software, which impedes model accountability
    and inadvertently abets inappropriate or misuse of models. Recently, model cards,
    a proposal for model documentation, have attracted notable attention, but their
    impact on the actual practice is unclear. In this work, we systematically study
    the model documentation in the field and investigate how to encourage more responsible
    and accountable documentation practice. Our analysis of publicly available model
    cards reveals a substantial gap between the proposal and the practice. We then
    design a tool named DocML aiming to (1) nudge the data scientists to comply with
    the model cards proposal during the model development, especially the sections
    related to ethics, and (2) assess and manage the documentation quality. A lab
    study reveals the benefit of our tool towards long-term documentation quality
    and accountability.
  githubURL: ''
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: docml
  otherURLs: []
  paperURL: https://arxiv.org/pdf/2204.06425.pdf
  releaseYear: 2023
  sourceType: paper
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{keplerglKeplerGlPowerful2019,\n  title = {Kepler.Gl: {{A}} Powerful\
    \ Open Source Geospatial Analysis Tool for Large-Scale Data Sets.},\n  author\
    \ = {Keplergl},\n  year = {2019},\n  url = {https://github.com/keplergl/kepler.gl},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Kepler.gl is a powerful open source geospatial analysis tool for large-scale
    data sets.
  githubURL: https://github.com/keplergl/kepler.gl/tree/master/bindings/kepler.gl-jupyter
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: keplergl
  otherURLs: []
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{pypathwayPyPathwayPythonPackage2022,\n  title = {{{PyPathway}}: {{A}}\
    \ Python Package for Pathway Visualization},\n  author = {PyPathway},\n  year\
    \ = {2022},\n  url = {https://github.com/iseekwonderful/PyPathway},\n  urldate\
    \ = {2023-04-24}\n}\n"
  communication: ''
  description: A python package for pathway visualization
  githubURL: https://github.com/iseekwonderful/PyPathway
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pypathway
  otherURLs: []
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{intelligentsystemslaborgOpen3DOpen3DModern2019,\n  title = {{{Open3D}}:\
    \ {{Open3D}}: {{A Modern Library}} for {{3D Data Processing}}},\n  author = {Intelligent\
    \ Systems Lab Org},\n  year = {2019},\n  url = {https://github.com/isl-org/Open3D},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: 'Open3D: A Modern Library for 3D Data Processing'
  githubURL: https://github.com/isl-org/Open3D
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: open3d
  otherURLs:
  - http://www.open3d.org/docs/release/tutorial/visualization/visualization.html
  - http://www.open3d.org/docs/release/tutorial/visualization/web_visualizer.html
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{facebookAxAdaptiveExperimentation2019,\n  title = {Ax: {{Adaptive\
    \ Experimentation Platform}}},\n  author = {Facebook},\n  year = {2019},\n  url\
    \ = {https://github.com/facebook/Ax},\n  urldate = {2023-04-24},\n  copyright\
    \ = {MIT},\n  howpublished = {Meta}\n}\n"
  communication: ''
  description: Ax is an accessible, general-purpose platform for understanding, managing,
    deploying, and automating adaptive experiments.
  githubURL: https://github.com/facebook/Ax
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: ax
  otherURLs:
  - https://ax.dev/versions/0.1.18/tutorials/visualizations.html
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{apacheApacheBeamUnified2019,\n  title = {Apache {{Beam}}: Unified\
    \ Programming Model for {{Batch}} and {{Streaming}} Data Processing},\n  author\
    \ = {Apache},\n  year = {2019},\n  url = {https://github.com/apache/beam},\n \
    \ urldate = {2023-04-24},\n  copyright = {Apache-2.0},\n  howpublished = {The\
    \ Apache Software Foundation}\n}\n"
  communication: ''
  description: Apache Beam is a unified programming model for Batch and Streaming
    data processing.
  githubURL: https://github.com/apache/beam
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: apache_beam
  otherURLs:
  - https://beam.apache.org/get-started/quickstart-py/
  - https://cloud.google.com/dataflow/docs/guides/interactive-pipeline-development
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@article{prokhorenkovaCatBoostUnbiasedBoosting2019,\n  title = {{{CatBoost}}:\
    \ Unbiased Boosting with Categorical Features},\n  shorttitle = {{{CatBoost}}},\n\
    \  author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and\
    \ Dorogush, Anna Veronika and Gulin, Andrey},\n  year = {2019},\n  url = {http://arxiv.org/abs/1706.09516},\n\
    \  urldate = {2023-04-14},\n  archiveprefix = {arxiv},\n  journal = {1706.09516}\n\
    }\n"
  communication: ''
  description: A fast, scalable, high performance Gradient Boosting on Decision Trees
    library, used for ranking, classification, regression and other machine learning
    tasks for Python, R, Java, C++. Supports computation on CPU and GPU.
  githubURL: https://github.com/catboost/catboost
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: catboost
  otherURLs:
  - https://catboost.ai/en/docs/features/visualization_jupyter-notebook
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@article{sivarajahTKETRetargetableCompiler2020,\n  title = {{{TKET}}: {{A}}\
    \ Retargetable Compiler for {{NISQ}} Devices},\n  author = {Sivarajah, Seyon and\
    \ Dilkes, Silas and Cowtan, Alexander and Simmons, Will and Edgington, Alec and\
    \ Duncan, Ross},\n  year = {2020},\n  journal = {Quantum Science and Technology},\n\
    \  volume = {6},\n  doi = {10.1088/2058-9565/ab8e92}\n}\n"
  communication: ''
  description: Source code for the TKET quantum compiler, Python bindings and utilities
  githubURL: https://github.com/CQCL/tket/tree/develop/pytket/pytket/circuit/display/js
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pytket
  otherURLs:
  - https://cqcl.github.io/tket/pytket/api/display.html
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{pengDataPrepEDATaskCentric2021,\n  title = {{{DataPrep}}.{{EDA}}:\
    \ {{Task-Centric Exploratory Data Analysis}} for {{Statistical Modeling}} in {{Python}}},\n\
    \  shorttitle = {{{DataPrep}}.{{EDA}}},\n  booktitle = {Proceedings of the 2021\
    \ {{International Conference}} on {{Management}} of {{Data}}},\n  author = {Peng,\
    \ Jinglin and Wu, Weiyuan and Lockhart, Brandon and Bian, Song and Yan, Jing Nathan\
    \ and Xu, Linghao and Chi, Zhixuan and Rzeszotarski, Jeffrey M. and Wang, Jiannan},\n\
    \  year = {2021},\n  doi = {10.1145/3448016.3457330},\n  url = {https://dl.acm.org/doi/10.1145/3448016.3457330},\n\
    \  urldate = {2022-11-20},\n  langid = {english}\n}\n"
  communication: ''
  description: Open-source low code data preparation library in python. Collect, clean
    and visualization your data in python with a few lines of code.
  githubURL: https://github.com/sfu-db/dataprep
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: dataprep
  otherURLs:
  - https://dataprep.ai/
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{krabelBamboolibGUIPandas2019,\n  title = {Bamboolib: {{GUI}} for\
    \ {{Pandas DataFrames}}},\n  author = {Krabel, Tobias},\n  year = {2019},\n  url\
    \ = {https://github.com/tkrabel/bamboolib},\n  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: bamboolib - a GUI for pandas DataFrames
  githubURL: https://github.com/tkrabel/bamboolib
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: bamboolib
  otherURLs:
  - https://docs.bamboolib.8080labs.com/documentation/getting-started
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{krauseDigitalEarthAustralia2021,\n  title = {Digital {{Earth Australia}}\
    \ Notebooks and Tools Repository},\n  author = {Krause, Claire and Dunn, Bex and\
    \ {Bishop-Taylor}, Robbi and Adams, Caitlin and Burton, Chad and Alger, Matthew\
    \ and Chua, Sean and Phillips, Claire and Newey, Vanessa and Kouzoubov, Kirill\
    \ and Leith, Alex and Ayers, Damien and Hicks, Andrew and {contributors}, DEA\
    \ Notebooks},\n  year = {2021},\n  doi = {10.26186/145234},\n  url = {https://github.com/GeoscienceAustralia/dea-notebooks/},\n\
    \  copyright = {Apache-2.0}\n}\n"
  communication: ''
  description: 'Repository for Digital Earth Australia Jupyter Notebooks: tools and
    workflows for geospatial analysis with Open Data Cube and Xarray'
  githubURL: https://github.com/GeoscienceAustralia/dea-notebooks
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: dea_tools
  otherURLs:
  - https://docs.dea.ga.gov.au/notebooks/Beginners_guide/05_Plotting.html
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{enthoughtMayavi3DVisualization2015,\n  title = {Mayavi: {{3D}} Visualization\
    \ of Scientific Data in {{Python}}},\n  shorttitle = {Mayavi},\n  author = {Enthought},\n\
    \  year = {2015},\n  url = {https://github.com/enthought/mayavi},\n  urldate =\
    \ {2023-04-24},\n  howpublished = {Enthought, Inc.}\n}\n"
  communication: ''
  description: 3D visualization of scientific data in Python
  githubURL: https://github.com/enthought/mayavi
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: mayavi
  otherURLs:
  - https://docs.enthought.com/mayavi/mayavi/
  paperURL: ''
  releaseYear: 2015
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{lightkurvecollaborationLightkurveKeplerTESS2018,\n  title = {Lightkurve:\
    \ {{Kepler}} and {{TESS}} Time Series Analysis in {{Python}}},\n  author = {{Lightkurve\
    \ Collaboration} and Cardoso, J. V. d. M. and Hedges, C. and {Gully-Santiago},\
    \ M. and Saunders, N. and Cody, A. M. and Barclay, T. and Hall, O. and Sagear,\
    \ S. and Turtelboom, E. and Zhang, J. and Tzanidakis, A. and Mighell, K. and Coughlin,\
    \ J. and Bell, K. and {Berta-Thompson}, Z. and Williams, P. and Dotson, J. and\
    \ Barentsen, G.},\n  year = {2018},\n  adsurl = {http://adsabs.harvard.edu/abs/2018ascl.soft12013L},\n\
    \  archiveprefix = {ascl},\n  howpublished = {Astrophysics Source Code Library}\n\
    }\n"
  communication: ''
  description: A friendly package for Kepler & TESS time series analysis in Python.
  githubURL: https://github.com/lightkurve/lightkurve
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: lightkurve
  otherURLs:
  - https://docs.lightkurve.org/
  paperURL: ''
  releaseYear: 2018
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{voxel51FiftyoneBuildingHighquality2020,\n  title = {Fiftyone: Building\
    \ High-Quality Datasets and Computer Vision Models},\n  author = {Voxel51},\n\
    \  year = {2020},\n  url = {https://github.com/voxel51/fiftyone},\n  urldate =\
    \ {2023-04-24},\n  copyright = {Apache-2.0},\n  howpublished = {Voxel51}\n}\n"
  communication: ''
  description: The open-source tool for building high-quality datasets and computer
    vision models
  githubURL: https://github.com/voxel51/fiftyone
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: fiftyone
  otherURLs:
  - https://docs.voxel51.com/
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{korobovELI5LibraryDebugging2016,\n  title = {{{ELI5}}: {{A}} Library\
    \ for Debugging/Inspecting Machine Learning Classifiers and Explaining Their Predictions},\n\
    \  author = {Korobov, Mikhail},\n  year = {2016},\n  url = {https://github.com/eli5-org/eli5},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT},\n  howpublished = {eli5-org}\n\
    }\n"
  communication: ''
  description: A library for debugging/inspecting machine learning classifiers and
    explaining their predictions
  githubURL: https://github.com/eli5-org/eli5
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: eli5
  otherURLs:
  - https://eli5.readthedocs.io/en/latest/
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{kingEscherBuildShare2016,\n  title = {Escher: {{Build}}, Share, and\
    \ Embed Visualizations of Metabolic Pathways},\n  author = {King, Zak},\n  year\
    \ = {2016},\n  url = {https://github.com/zakandrewking/escher},\n  urldate = {2023-04-24}\n\
    }\n"
  communication: ''
  description: Build, share, and embed visualizations of metabolic pathways.
  githubURL: https://github.com/zakandrewking/escher
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: escher
  otherURLs:
  - https://escher.readthedocs.io/en/latest/escher-python.html
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@article{cholletKeras2015,\n  title = {Keras},\n  author = {Chollet, Fran{\\\
    c c}ois},\n  year = {2015},\n  url = {https://keras.io}\n}\n"
  communication: ''
  description: Keras is a deep learning API written in Python, running on top of the
    machine learning platform TensorFlow. It was developed with a focus on enabling
    fast experimentation and providing a delightful developer experience.
  githubURL: https://github.com/keras-team/keras
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: keras
  otherURLs:
  - https://faroit.com/keras-docs/2.0.8/visualization/
  paperURL: ''
  releaseYear: 2015
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{kleinFlexxWriteDesktop2016,\n  title = {Flexx: {{Write}} Desktop\
    \ and Web Apps in Pure {{Python}}},\n  author = {Klein, Almar},\n  year = {2016},\n\
    \  url = {https://github.com/flexxui/flexx},\n  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Write desktop and web apps in pure Python
  githubURL: https://github.com/flexxui/flexx
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: flexx
  otherURLs:
  - https://flexx.readthedocs.io/en/stable/
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{petrakPythongatenlpPythonText2020,\n  title = {Python-Gatenlp: {{Python}}\
    \ Text Processing, Pattern Matching, and {{NLP}} Framework},\n  author = {Petrak,\
    \ Johann},\n  year = {2020},\n  url = {https://github.com/GateNLP/python-gatenlp},\n\
    \  urldate = {2023-04-24},\n  copyright = {Apache-2.0},\n  howpublished = {GateNLP}\n\
    }\n"
  communication: ''
  description: Write desktop and web apps in pure Python
  githubURL: https://github.com/GateNLP/python-gatenlp
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: gatenlp
  otherURLs:
  - https://gatenlp.github.io/python-gatenlp/visualization.html
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{rudigerGeoviewsSimpleConcise2016,\n  title = {Geoviews: {{Simple}},\
    \ Concise Geographical Visualization in {{Python}}},\n  author = {Rudiger, Philipp},\n\
    \  year = {2016},\n  url = {https://github.com/holoviz/geoviews},\n  urldate =\
    \ {2023-04-24},\n  copyright = {BSD-3-Clause},\n  howpublished = {HoloViz}\n}\n"
  communication: ''
  description: Simple, concise geographical visualization in Python
  githubURL: https://github.com/holoviz/geoviews
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: geoviews
  otherURLs:
  - https://geoviews.org/
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{germanidisPigeonQuicklyAnnotate2017a,\n  title = {Pigeon: {{Quickly}}\
    \ Annotate Data from the Comfort of Your {{Jupyter}} Notebook},\n  author = {Germanidis,\
    \ Anastasis},\n  year = {2017},\n  url = {https://github.com/agermanidis/pigeon},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Quickly annotate data from the comfort of your Jupyter notebook.
  githubURL: https://github.com/agermanidis/pigeon
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pigeon
  otherURLs: []
  paperURL: ''
  releaseYear: 2017
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{autodeskNotebookMolecularVisualization2016,\n  title = {Notebook\
    \ {{Molecular Visualization}}},\n  author = {Autodesk},\n  year = {2016},\n  url\
    \ = {https://github.com/Autodesk/notebook-molecular-visualization},\n  urldate\
    \ = {2023-04-24}\n}\n"
  communication: ''
  description: 2D and 3D molecular visualization in Jupyter notebooks using 3DMol.js
    and D3.js.
  githubURL: https://github.com/Autodesk/notebook-molecular-visualization
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: py3dmol
  otherURLs: []
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{sievertLDAvisMethodVisualizing2014,\n  title = {{{LDAvis}}:\
    \ {{A}} Method for Visualizing and Interpreting Topics},\n  booktitle = {Proceedings\
    \ of the Workshop on Interactive Language Learning, Visualization, and Interfaces},\n\
    \  author = {Sievert, Carson and Shirley, Kenneth},\n  year = {2014},\n  doi =\
    \ {10.3115/v1/W14-3110},\n  url = {https://aclanthology.org/W14-3110}\n}\n"
  communication: ''
  description: Python library for interactive topic model visualization. Port of the
    R LDAvis package.
  githubURL: https://github.com/bmabey/pyLDAvis
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pyldavis
  otherURLs: []
  paperURL: ''
  releaseYear: 2014
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{bqplotBqplotPlottingLibrary2016,\n  title = {Bqplot: {{Plotting}}\
    \ Library for {{IPython}}/{{Jupyter}} Notebooks},\n  author = {Bqplot},\n  year\
    \ = {2016},\n  url = {https://github.com/bqplot/bqplot},\n  urldate = {2023-04-24}\n\
    }\n"
  communication: ''
  description: Plotting library for IPython/Jupyter notebooks.
  githubURL: https://github.com/bqplot/bqplot
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: bqplot
  otherURLs: []
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{gonzalezHciplotLibraryVisualizing2019,\n  title = {Hciplot: {{Library}}\
    \ for Visualizing High-Contrast Imaging Multidimensional Datacubes on {{JupyterLab}}},\n\
    \  author = {Gonzalez, Carlos},\n  year = {2019},\n  url = {https://github.com/carlos-gg/hciplot},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Library for visualizing high-contrast imaging multidimensional datacubes
    on JupyterLab.
  githubURL: https://github.com/carlos-gg/hciplot
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: hciplot
  otherURLs: []
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{borelliPypotreePotreeJupyter2019,\n  title = {Pypotree: Potree for\
    \ Jupyter Notebooks and Colab},\n  author = {Borelli, Centre},\n  year = {2019},\n\
    \  url = {https://github.com/centreborelli/pypotree},\n  urldate = {2023-04-24}\n\
    }\n"
  communication: ''
  description: Allows to insert potree cells into jupyter and colab notebooks.
  githubURL: https://github.com/centreborelli/pypotree
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pypotree
  otherURLs:
  - https://github.com/potree/potree/
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{eppersonAutoProfilerAutomaticallyProfile2022,\n  title = {{{AutoProfiler}}:\
    \ {{Automatically}} Profile Dataframes in the {{Jupyter}} Sidebar},\n  author\
    \ = {Epperson, Will},\n  year = {2022},\n  url = {https://github.com/cmudig/AutoProfiler},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Automatically profile dataframes in the Jupyter sidebar.
  githubURL: https://github.com/cmudig/AutoProfiler
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: digautoprofiler
  otherURLs: []
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{cuemacroChartpyEasyUse2016,\n  title = {Chartpy: {{Easy}} to Use\
    \ {{Python API}} Wrapper to Plot Charts with Matplotlib, Plotly, Bokeh and More},\n\
    \  author = {Cuemacro},\n  year = {2016},\n  url = {https://github.com/cuemacro/chartpy},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Easy to use Python API wrapper to plot charts with matplotlib, plotly,
    bokeh and more.
  githubURL: https://github.com/cuemacro/chartpy
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: chartpy
  otherURLs: []
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@article{saleiroAequitasBiasFairness2019,\n  title = {Aequitas: {{A Bias}}\
    \ and {{Fairness Audit Toolkit}}},\n  shorttitle = {Aequitas},\n  author = {Saleiro,\
    \ Pedro and Kuester, Benedict and Hinkson, Loren and London, Jesse and Stevens,\
    \ Abby and Anisfeld, Ari and Rodolfa, Kit T. and Ghani, Rayid},\n  year = {2019},\n\
    \  url = {http://arxiv.org/abs/1811.05577},\n  urldate = {2023-04-21},\n  archiveprefix\
    \ = {arxiv},\n  journal = {1811.05577}\n}\n"
  communication: ''
  description: Bias and Fairness Audit Toolkit.
  githubURL: https://github.com/dssg/aequitas
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: aequitas
  otherURLs: []
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{facebookHiPlotMakesUnderstanding2020,\n  title = {{{HiPlot}} Makes\
    \ Understanding High Dimensional Data Easy},\n  author = {Facebook},\n  year =\
    \ {2020},\n  url = {https://github.com/facebookresearch/hiplot},\n  urldate =\
    \ {2023-04-24}\n}\n"
  communication: ''
  description: HiPlot makes understanding high dimensional data easy.
  githubURL: https://github.com/facebookresearch/hiplot
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: hiplot
  otherURLs: []
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{steinPerspectiveInteractiveAnalytics2022,\n  title = {Perspective:\
    \ Interactive Analytics and Data Visualization Component},\n  author = {Stein,\
    \ Andrew},\n  year = {2022},\n  url = {https://github.com/finos/perspective},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: A data visualization and analytics component, especially well-suited
    for large and/or streaming datasets.
  githubURL: https://github.com/finos/perspective
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: perspective
  otherURLs:
  - https://perspective.finos.org/
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{googleBraxMassivelyParallel2021,\n  title = {Brax: {{Massively}}\
    \ Parallel Rigidbody Physics Simulation on Accelerator Hardware.},\n  author =\
    \ {Google},\n  year = {2021},\n  url = {https://github.com/google/brax},\n  urldate\
    \ = {2023-04-24}\n}\n"
  communication: ''
  description: Massively parallel rigidbody physics simulation on accelerator hardware.
  githubURL: https://github.com/google/brax
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: brax
  otherURLs: []
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{graphistryPyGraphistryExploreRelationships2016,\n  title = {{{PyGraphistry}}:\
    \ {{Explore Relationships}}},\n  author = {Graphistry},\n  year = {2016},\n  url\
    \ = {https://github.com/graphistry/pygraphistry},\n  urldate = {2023-04-24}\n\
    }\n"
  communication: ''
  description: PyGraphistry is a Python library to quickly load, shape, embed, and
    explore big graphs with the GPU-accelerated Graphistry visual graph analyzer.
  githubURL: https://github.com/graphistry/pygraphistry
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: graphistry
  otherURLs: []
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{microsoftInterpretCommunitySDK2019,\n  title = {Interpret {{Community\
    \ SDK}}},\n  author = {Microsoft},\n  year = {2019},\n  url = {https://github.com/interpretml/interpret-community},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Interpret Community extends Interpret repository with additional interpretability
    techniques and utility functions to handle real-world datasets and workflows..
  githubURL: https://github.com/interpretml/interpret-community
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: interpret_community
  otherURLs: []
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{kukushkinIpyannotateJupyterWidget2018,\n  title = {Ipyannotate: {{Jupyter\
    \ Widget}} for Data Annotation},\n  author = {Kukushkin, Alexander},\n  year =\
    \ {2018},\n  url = {https://github.com/ipyannotate/ipyannotate},\n  urldate =\
    \ {2023-04-24}\n}\n"
  communication: ''
  description: Jupyter Widget for data annotation.
  githubURL: https://github.com/ipyannotate/ipyannotate
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: ipyannotate
  otherURLs: []
  paperURL: ''
  releaseYear: 2018
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{vigMultiscaleVisualizationAttention2019,\n  title = {A Multiscale\
    \ Visualization of Attention in the Transformer Model},\n  booktitle = {Proceedings\
    \ of the 57th Annual Meeting of the Association for Computational Linguistics:\
    \ {{System}} Demonstrations},\n  author = {Vig, Jesse},\n  year = {2019},\n  doi\
    \ = {10.18653/v1/P19-3007},\n  url = {https://aclanthology.org/P19-3007}\n}\n"
  communication: ''
  description: 'BertViz: Visualize Attention in NLP Models (BERT, GPT2, BART, etc.).'
  githubURL: https://github.com/jessevig/bertviz
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: bertviz
  otherURLs: []
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{warmerdamGoingTSNEExposing2020,\n  title = {Going beyond\
    \ {{T-SNE}}: {{Exposing}} Whatlies in Text Embeddings},\n  booktitle = {Proceedings\
    \ of Second Workshop for {{NLP}} Open Source Software ({{NLP-OSS}})},\n  author\
    \ = {Warmerdam, Vincent and Kober, Thomas and Tatman, Rachael},\n  year = {2020},\n\
    \  doi = {10.18653/v1/2020.nlposs-1.8},\n  url = {https://www.aclweb.org/anthology/2020.nlposs-1.8}\n\
    }\n"
  communication: ''
  description: Toolkit to help understand "what lies" in word embeddings. Also benchmarking!
  githubURL: https://github.com/koaning/whatlies
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: whatlies
  otherURLs: []
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{maeztuNeo4jupyterQuickVisualization2016,\n  title = {Neo4jupyter:\
    \ {{A}} Quick Visualization Tool for {{Jupyter}} and {{Neo4J}}},\n  author = {Maeztu,\
    \ Gabi},\n  year = {2016},\n  url = {https://github.com/merqurio/neo4jupyter},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: A quick visualization tool for Jupyter and Neo4J.
  githubURL: https://github.com/merqurio/neo4jupyter
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: neo4jupyter
  otherURLs: []
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{woutsItablesPandasDataFrames2019,\n  title = {Itables: {{Pandas DataFrames}}\
    \ as {{Interactive DataTables}}},\n  author = {Wouts, Marc},\n  year = {2019},\n\
    \  url = {https://github.com/mwouts/itables},\n  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Pandas DataFrames as Interactive DataTables.
  githubURL: https://github.com/mwouts/itables
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: itables
  otherURLs: []
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{hlobilPandasBokehBokehPlotting2018,\n  title = {Pandas-{{Bokeh}}:\
    \ {{Bokeh Plotting Backend}} for {{Pandas}} and {{GeoPandas}}},\n  author = {Hlobil,\
    \ Patrik},\n  year = {2018},\n  url = {https://github.com/PatrikHlobil/Pandas-Bokeh},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Bokeh Plotting Backend for Pandas and GeoPandas.
  githubURL: https://github.com/PatrikHlobil/Pandas-Bokeh
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pandas_bokeh
  otherURLs: []
  paperURL: ''
  releaseYear: 2018
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{poliastroCzml3PythonLibrary2019,\n  title = {Czml3: {{Python}} 3\
    \ Library to Write {{CZML}}},\n  author = {Poliastro},\n  year = {2019},\n  url\
    \ = {https://github.com/poliastro/czml3},\n  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Python 3 library to write CZML.
  githubURL: https://github.com/poliastro/czml3
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: czml3
  otherURLs: []
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{fernandesFoliumPythonData2019,\n  title = {Folium: {{Python Data}}.\
    \ {{Leaflet}}.Js {{Maps}}},\n  author = {Fernandes, Filipe},\n  year = {2019},\n\
    \  url = {https://github.com/python-visualization/folium},\n  urldate = {2023-04-24}\n\
    }\n"
  communication: ''
  description: Python Data. Leaflet.js Maps.
  githubURL: https://github.com/python-visualization/folium
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: folium
  otherURLs: []
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{kissingerPyZXLargeScale2020,\n  title = {{{PyZX}}: {{Large}}\
    \ Scale Automated Diagrammatic Reasoning},\n  booktitle = {Proceedings 16th International\
    \ Conference on Quantum Physics and Logic, Chapman University, Orange, {{CA}},\
    \ {{USA}}., 10-14 June 2019},\n  author = {Kissinger, Aleks and {van de Wetering},\
    \ John},\n  year = {2020},\n  series = {Electronic Proceedings in Theoretical\
    \ Computer Science},\n  volume = {318},\n  doi = {10.4204/EPTCS.318.14}\n}\n"
  communication: ''
  description: Python library for quantum circuit rewriting and optimisation using
    the ZX-calculus.
  githubURL: https://github.com/Quantomatic/pyzx
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pyzx
  otherURLs:
  - https://pyzx.readthedocs.io/en/stable/graph.html
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{googleTensorFlowModelAnalysis2018,\n  title = {{{TensorFlow Model\
    \ Analysis}}},\n  author = {Google},\n  year = {2018},\n  url = {https://github.com/tensorflow/model-analysis},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Model analysis tools for TensorFlow.
  githubURL: https://github.com/tensorflow/model-analysis
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: tensorflow_model_analysis
  otherURLs: []
  paperURL: ''
  releaseYear: 2018
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{abadiTensorFlowSystemLargescale2016,\n  title = {{{TensorFlow}}:\
    \ {{A}} System for Large-Scale Machine Learning},\n  booktitle = {12th {{USENIX}}\
    \ Symposium on Operating Systems Design and Implementation ({{OSDI}} 16)},\n \
    \ author = {Abadi, Mart{\\'i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng\
    \ and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and\
    \ Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh\
    \ and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit\
    \ and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and\
    \ Yu, Yuan and Zheng, Xiaoqiang},\n  year = {2016}\n}\n"
  communication: ''
  description: TensorFlow's Visualization Toolkit.
  githubURL: https://github.com/tensorflow/tensorboard
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: tensorboard
  otherURLs:
  - https://www.tensorflow.org/tensorboard
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{durantIntakeGeneralInterface2018,\n  title = {Intake: {{A}} General\
    \ Interface for Loading Data},\n  shorttitle = {Intake},\n  author = {Durant,\
    \ Martin},\n  year = {2018},\n  url = {https://github.com/intake/intake},\n  urldate\
    \ = {2023-04-24},\n  copyright = {BSD-2-Clause},\n  howpublished = {Intake}\n\
    }\n"
  communication: ''
  description: Intake is a lightweight package for finding, investigating, loading
    and disseminating data.
  githubURL: https://github.com/intake/intake
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: intake
  otherURLs:
  - https://intake.readthedocs.io/en/latest/gui.html
  paperURL: ''
  releaseYear: 2018
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{franzCytoscapeCytoscapeJs2022,\n  title = {Cytoscape/Cytoscape.Js},\n\
    \  shorttitle = {Cytoscape/Cytoscape.Js},\n  author = {Franz, Max and Cheung,\
    \ Manfred and Sumer, Onur and Huck, Gerardo and Fong, Dylan and {R-Ba} and Josejulio\
    \ Mart{\\'i}nez and {\\v Z}{\\'a}k, Jan and Mullen, Tony and Chadkin, Bogdan and\
    \ Ayhun and Metincansiper and Chris and Hartmann, Jan and Stahl, Joseph and Parlapiano,\
    \ Paolo and Sherer, Eli and Gauthier, M{\\'e}lanie and Trott, Rich and Sidlovsky,\
    \ Yaroslav and Bumbu and Li, Alexander and Lopes, Christian and TexKiller and\
    \ Beynon, Mike and Meira, Gui and Janit Mehta and Dias, Mike},\n  year = {2022},\n\
    \  doi = {10.5281/ZENODO.6828253},\n  url = {https://zenodo.org/record/6828253},\n\
    \  urldate = {2023-04-24},\n  copyright = {Open Access},\n  howpublished = {Zenodo}\n\
    }\n"
  communication: ''
  description: Graph theory (network) library for visualisation and analysis.
  githubURL: https://github.com/cytoscape/cytoscape.js
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: cytoscapejs
  otherURLs:
  - https://js.cytoscape.org/
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{keLightGBMHighlyEfficient2017,\n  title = {{{LightGBM}}:\
    \ {{A}} Highly Efficient Gradient Boosting Decision Tree},\n  booktitle = {Advances\
    \ in Neural Information Processing Systems 30 ({{NIP}} 2017)},\n  author = {Ke,\
    \ Guolin and Meng, Qi and Finely, Thomas and Wang, Taifeng and Chen, Wei and Ma,\
    \ Weidong and Ye, Qiwei and Liu, Tie-Yan},\n  year = {2017},\n  url = {https://www.microsoft.com/en-us/research/publication/lightgbm-a-highly-efficient-gradient-boosting-decision-tree/}\n\
    }\n"
  communication: ''
  description: A fast, distributed, high performance gradient boosting (GBT, GBDT,
    GBRT, GBM or MART) framework based on decision tree algorithms, used for ranking,
    classification and many other machine learning tasks.
  githubURL: https://github.com/microsoft/LightGBM
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: lightgbm
  otherURLs:
  - https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.plot_tree.html
  paperURL: ''
  releaseYear: 2017
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@article{grootendorstBERTopicNeuralTopic2022,\n  title = {{{BERTopic}}:\
    \ {{Neural}} Topic Modeling with a Class-Based {{TF-IDF}} Procedure},\n  author\
    \ = {Grootendorst, Maarten},\n  year = {2022},\n  journal = {arXiv preprint arXiv:2203.05794},\n\
    \  doi = {10.48550/arXiv.2203.05794},\n  archiveprefix = {arxiv}\n}\n"
  communication: ''
  description: Leveraging BERT and c-TF-IDF to create easily interpretable topics.
  githubURL: https://github.com/MaartenGr/BERTopic
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: bertopic
  otherURLs:
  - https://maartengr.github.io/BERTopic/index.html
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{autovimlAutoVizAutomaticallyVisualize2020,\n  title = {{{AutoViz}}:\
    \ {{Automatically Visualize}} Any Dataset, Any Size with a Single Line of Code},\n\
    \  author = {AutoViML},\n  year = {2020},\n  url = {https://github.com/AutoViML/AutoViz},\n\
    \  urldate = {2023-04-24},\n  copyright = {Apache-2.0}\n}\n"
  communication: ''
  description: Automatically Visualize any dataset, any size with a single line of
    code.
  githubURL: https://github.com/AutoViML/AutoViz
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: autovizwidget
  otherURLs: []
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@article{abrahamMachineLearningNeuroimaging2014,\n  title = {Machine Learning\
    \ for Neuroimaging with Scikit-Learn},\n  author = {Abraham, Alexandre and Pedregosa,\
    \ Fabian and Eickenberg, Michael and Gervais, Philippe and Mueller, Andreas and\
    \ Kossaifi, Jean and Gramfort, Alexandre and Thirion, Bertrand and Varoquaux,\
    \ Ga{\\\"e}l},\n  year = {2014},\n  journal = {Frontiers in Neuroinformatics},\n\
    \  volume = {8},\n  doi = {10.3389/fninf.2014.00014},\n  url = {http://journal.frontiersin.org/article/10.3389/fninf.2014.00014/abstract},\n\
    \  urldate = {2023-04-17}\n}\n"
  communication: ''
  description: Machine learning for NeuroImaging in Python.
  githubURL: https://github.com/nilearn/nilearn
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: nilearn
  otherURLs:
  - https://nilearn.github.io/stable/index.html
  - https://nilearn.github.io/stable/plotting/index.html#interactive-plots
  paperURL: ''
  releaseYear: 2014
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{qustarKaleidoscopeVisualizationsQuantum2019,\n  title = {Kaleidoscope:\
    \ {{Visualizations}} for Quantum Computing.},\n  author = {QuSTaR},\n  year =\
    \ {2019},\n  url = {https://github.com/QuSTaR/kaleidoscope},\n  urldate = {2023-04-24}\n\
    }\n"
  communication: ''
  description: Kaleidoscope - Visualizations for quantum computing.
  githubURL: https://github.com/QuSTaR/kaleidoscope
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: kaleidoscope
  otherURLs:
  - https://nonhermitian.org/kaleido/index.html
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{rudigerPanelHighlevelApp2021,\n  title = {Panel: {{A}} High-Level\
    \ App and Dashboarding Solution for {{Python}}},\n  shorttitle = {Panel},\n  author\
    \ = {Rudiger, Philipp},\n  year = {2021},\n  url = {https://github.com/holoviz/panel},\n\
    \  urldate = {2023-04-24},\n  copyright = {BSD-3-Clause},\n  howpublished = {HoloViz}\n\
    }\n"
  communication: ''
  description: A high-level app and dashboarding solution for Python.
  githubURL: https://github.com/holoviz/panel
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: panel
  otherURLs:
  - https://panel.holoviz.org/
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{pixiedustPixieDustPythonHelper2016,\n  title = {{{PixieDust}}: {{Python\
    \ Helper}} Library for {{Jupyter Notebooks}}},\n  author = {PixieDust},\n  year\
    \ = {2016},\n  url = {https://github.com/pixiedust/pixiedust},\n  urldate = {2023-04-24},\n\
    \  copyright = {Apache-2.0},\n  howpublished = {Pixiedust development}\n}\n"
  communication: ''
  description: Python Helper library for Jupyter Notebooks.
  githubURL: https://github.com/pixiedust/pixiedust
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pixiedust
  otherURLs:
  - https://pixiedust.github.io/pixiedust/displayapi.html
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{parmerDashDataApps2020,\n  title = {Dash: {{Data Apps}} \\& {{Dashboards}}\
    \ for {{Python}}},\n  author = {Parmer, Chris},\n  year = {2020},\n  url = {https://github.com/plotly/dash},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT},\n  howpublished = {Plotly}\n\
    }\n"
  communication: ''
  description: Data Apps & Dashboards for Python. No JavaScript Required.
  githubURL: https://github.com/plotly/dash
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: dash
  otherURLs:
  - https://plotly.com/dash/
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{boucasPy2cytoscapePythonUtilities2015,\n  title = {Py2cytoscape:\
    \ {{Python}} Utilities for {{Cytoscape}} and {{Cytoscape}}.Js},\n  author = {Boucas,\
    \ Jorge},\n  year = {2015},\n  url = {https://github.com/cytoscape/py2cytoscape},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT},\n  howpublished = {Cytoscape\
    \ Consortium}\n}\n"
  communication: ''
  description: Python utilities for Cytoscape and Cytoscape.js.
  githubURL: https://github.com/cytoscape/py2cytoscape
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: py2cytoscape
  otherURLs:
  - https://js.cytoscape.org/
  paperURL: ''
  releaseYear: 2015
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{baumPyCaretOpensourceLowcode2020,\n  title = {{{PyCaret}}: {{An}}\
    \ Open-Source, Low-Code Machine Learning Library in {{Python}}},\n  author = {Baum,\
    \ Antoni},\n  year = {2020},\n  url = {https://github.com/pycaret/pycaret},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT},\n  howpublished = {PyCaret}\n\
    }\n"
  communication: ''
  description: An open-source, low-code machine learning library in Python.
  githubURL: https://github.com/pycaret/pycaret
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pycaret
  otherURLs:
  - https://analyticsindiamag.com/how-to-visualize-different-ml-models-using-pycaret-for-optimization/
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{mauricioPydgridPythonDistribution2017,\n  title = {Pydgrid: {{Python\
    \ Distribution Grid Simulator}}},\n  author = {Mauricio, Juan Manuel},\n  year\
    \ = {2017},\n  url = {https://github.com/pydgrid/pydgrid},\n  urldate = {2023-04-24}\n\
    }\n"
  communication: ''
  description: Python Distribution Grid simulator.
  githubURL: https://github.com/pydgrid/pydgrid
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pydgrid
  otherURLs:
  - https://pydgrid.readthedocs.io/en/latest/
  paperURL: ''
  releaseYear: 2017
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{sampaioPyMovePythonLibrary2018,\n  title = {{{PyMove}}: {{Python}}\
    \ Library to Simplify Queries and Visualization of Trajectories and Other Spatial-Temporal\
    \ Data},\n  author = {Sampaio, Matheus Xavier},\n  year = {2018},\n  url = {https://github.com/InsightLab/PyMove},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT},\n  howpublished = {Insight Data\
    \ Science Lab}\n}\n"
  communication: ''
  description: PyMove is a Python library to simplify queries and visualization of
    trajectories and other spatial-temporal data.
  githubURL: https://github.com/InsightLab/PyMove
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pymove
  otherURLs:
  - https://pymove.readthedocs.io/en/latest/
  - https://pymove.readthedocs.io/en/latest/examples/03_Exploring_Visualization.html
  paperURL: ''
  releaseYear: 2018
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{intuitivetextminingD3fdgraphD3Interactive2019,\n  title = {D3fdgraph:\
    \ D3 Interactive Animated Force-Directed Graphs in a Jupyter Notebook},\n  author\
    \ = {Intuitive Text Mining},\n  year = {2019},\n  url = {https://github.com/intuitivetextmining/d3fdgraph},\n\
    \  urldate = {2023-04-24},\n  copyright = {GPL-2.0}\n}\n"
  communication: ''
  description: d3 interactive animated force-directed graphs in a jupyter notebook.
  githubURL: https://github.com/intuitivetextmining/d3fdgraph
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: d3fdgraph
  otherURLs:
  - https://pypi.org/project/d3fdgraph/
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{guptaDataPurifierPythonLibrary2021,\n  title = {Data-{{Purifier}}:\
    \ {{A Python}} Library for {{Automated Exploratory Data Analysis}}},\n  author\
    \ = {Gupta, Abhishek},\n  year = {2021},\n  url = {https://github.com/Elysian01/Data-Purifier},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT}\n}\n"
  communication: ''
  description: A Python library for Automated Exploratory Data Analysis, Automated
    Data Cleaning, and Automated Data Preprocessing For Machine Learning and Natural
    Language Processing Applications in Python.
  githubURL: https://github.com/Elysian01/Data-Purifier
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: datapurifier
  otherURLs:
  - https://pypi.org/project/data-purifier/
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{datapaneDatapaneBuildFullstack2023,\n  title = {Datapane: {{Build}}\
    \ Full-Stack Data Apps in 100\\% {{Python}}},\n  author = {Datapane},\n  year\
    \ = {2023},\n  url = {https://github.com/datapane/datapane},\n  urldate = {2023-04-24},\n\
    \  copyright = {Apache-2.0},\n  howpublished = {Datapane}\n}\n"
  communication: ''
  description: Build full-stack data apps in 100% Python.
  githubURL: https://github.com/datapane/datapane
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: datapane
  otherURLs:
  - https://pypi.org/project/datapane/
  paperURL: ''
  releaseYear: 2023
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{robinsonModuleEmbeddingIgv2022,\n  title = {Module for Embedding\
    \ Igv.Js in an {{IPython}} Notebook},\n  author = {Robinson, Jim},\n  year = {2022},\n\
    \  url = {https://github.com/igvteam/igv-notebook},\n  urldate = {2023-04-24}\n\
    }\n"
  communication: ''
  description: Module for embedding igv.js in an IPython notebook.
  githubURL: https://github.com/igvteam/igv-notebook
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: igv
  otherURLs:
  - https://pypi.org/project/igv/
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{fullerImoleculeEmbeddableWebGL2013,\n  title = {Imolecule: {{An}}\
    \ Embeddable {{webGL}} Molecule Viewer and File Format Converter},\n  author =\
    \ {Fuller, Patrick},\n  year = {2013},\n  url = {https://github.com/patrickfuller/imolecule},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT}\n}\n"
  communication: ''
  description: An embeddable webGL molecule viewer and file format converter.
  githubURL: https://github.com/patrickfuller/imolecule
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: imolecule
  otherURLs:
  - https://pypi.org/project/imolecule/
  paperURL: ''
  releaseYear: 2013
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{mccormickInsightSoftwareConsortiumItkwidgetsItkwidgets2022,\n  title\
    \ = {{{InsightSoftwareConsortium}}/Itkwidgets: Itkwidgets 0.32.5},\n  shorttitle\
    \ = {{{InsightSoftwareConsortium}}/Itkwidgets},\n  author = {McCormick, Matt and\
    \ Major, Brianna and Laryssa Abdala and Elliott, Paul and Aylward, Stephen R.},\n\
    \  year = {2022},\n  doi = {10.5281/ZENODO.7489693},\n  url = {https://zenodo.org/record/7489693},\n\
    \  urldate = {2023-04-24},\n  copyright = {Open Access},\n  howpublished = {Zenodo}\n\
    }\n"
  communication: ''
  description: Interactive Jupyter widgets to visualize images, point sets, and meshes
    in 2D and 3D.
  githubURL: https://github.com/InsightSoftwareConsortium/itkwidgets
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: itkwidgets
  otherURLs:
  - https://pypi.org/project/itkwidgets/
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{fullerJgraphEmbeddableWebGL2013,\n  title = {Jgraph: {{An}} Embeddable\
    \ {{webGL}} Graph Visualization Library},\n  author = {Fuller, Patrick},\n  year\
    \ = {2013},\n  url = {https://github.com/patrickfuller/jgraph},\n  urldate = {2023-04-24},\n\
    \  copyright = {MIT}\n}\n"
  communication: ''
  description: An embeddable webGL graph visualization library.
  githubURL: https://github.com/patrickfuller/jgraph
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: jgraph
  otherURLs:
  - https://pypi.org/project/jgraph/
  paperURL: ''
  releaseYear: 2013
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{jupyterphysicalsciencelabJupyterPiDAQInteractiveAnalog2020,\n  title\
    \ = {{{JupyterPiDAQ}}: {{Interactive}} Analog Data Acquisition and Analysis within\
    \ {{Jupyter}} Notebooks Using {{GUI}} Tools},\n  author = {Jupyter Physical Science\
    \ Lab},\n  year = {2020},\n  url = {https://github.com/JupyterPhysSciLab/JupyterPiDAQ},\n\
    \  urldate = {2023-04-24},\n  copyright = {GPL-3.0},\n  howpublished = {Jupyter\
    \ Physical Science Lab}\n}\n"
  communication: ''
  description: Interactive analog data acquisition and analysis within Jupyter notebooks
    using GUI tools.
  githubURL: https://github.com/JupyterPhysSciLab/JupyterPiDAQ
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: jupyterpidaq
  otherURLs:
  - https://pypi.org/project/JupyterPiDAQ/0.7.4/
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{dupreJyquickhelperHelpersJupyter2016,\n  title = {Jyquickhelper:\
    \ {{Helpers}} for {{Jupyter}} Notebooks around Javascript},\n  author = {{dupr{\\\
    'e}}, xavier},\n  year = {2016},\n  url = {https://github.com/sdpython/jyquickhelper},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT}\n}\n"
  communication: ''
  description: Helpers for Jupyter notebooks around javascript.
  githubURL: https://github.com/sdpython/jyquickhelper
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: jyquickhelper
  otherURLs:
  - https://pypi.org/project/jyquickhelper/
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{bouyssetMols2gridInteractiveMolecule2021,\n  title = {Mols2grid -\
    \ {{Interactive}} Molecule Viewer for {{2D}} Structures},\n  author = {Bouysset,\
    \ C{\\'e}dric},\n  year = {2021},\n  doi = {10.5281/zenodo.6591473},\n  url =\
    \ {https://github.com/cbouy/mols2grid},\n  copyright = {Apache-2.0}\n}\n"
  communication: ''
  description: Mols2grid is an interactive molecule viewer for 2D structures, based
    on RDKit.
  githubURL: https://github.com/cbouy/mols2grid
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: mols2grid
  otherURLs:
  - https://pypi.org/project/mols2grid/
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{brugmanPandasprofilingExploratoryData2019,\n  title = {Pandas-Profiling:\
    \ {{Exploratory}} Data Analysis for Python},\n  author = {Brugman, Simon},\n \
    \ year = {2019},\n  url = {https://github.com/pandas-profiling/pandas-profiling}\n\
    }\n"
  communication: ''
  description: Create HTML profiling reports from pandas DataFrame objects.
  githubURL: https://github.com/ydataai/ydata-profiling
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pandas_profiling
  otherURLs:
  - https://pypi.org/project/pandas-profiling/
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{rosePandasGUIGUIPandas2020,\n  title = {{{PandasGUI}}: {{A GUI}}\
    \ for {{Pandas DataFrames}}},\n  author = {Rose, Adam},\n  year = {2020},\n  url\
    \ = {https://github.com/adamerose/PandasGUI},\n  urldate = {2023-04-24},\n  copyright\
    \ = {MIT-0}\n}\n"
  communication: ''
  description: PandasGUI is a GUI for viewing, plotting and analyzing Pandas DataFrames.
  githubURL: https://github.com/adamerose/PandasGUI
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pandasgui
  otherURLs:
  - https://pypi.org/project/pandasgui/
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{uberDeckGlWebGL22016,\n  title = {Deck.Gl: {{WebGL2}} Powered Geospatial\
    \ Visualization Layers},\n  author = {{Uber}},\n  year = {2016},\n  url = {https://deck.gl},\n\
    \  urldate = {2020-05-29}\n}\n"
  communication: ''
  description: WebGL2 powered visualization framework.
  githubURL: https://github.com/visgl/deck.gl
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pydeck
  otherURLs:
  - https://pypi.org/project/pydeck/
  - https://pydeck.gl/jupyter.html
  paperURL: ''
  releaseYear: 2016
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@article{cheginiHyRiverHydroclimateData2021,\n  title = {{{HyRiver}}: {{Hydroclimate}}\
    \ Data Retriever},\n  author = {Chegini, Taher and Li, Hong-Yi and Leung, L. Ruby},\n\
    \  year = {2021},\n  journal = {Journal of Open Source Software},\n  volume =\
    \ {6},\n  doi = {10.21105/joss.03175},\n  url = {https://github.com/hyriver/pygeohydro}\n\
    }\n"
  communication: ''
  description: A part of HyRiver software stack for accessing hydrology data through
    web services.
  githubURL: https://github.com/hyriver/pygeohydro
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pygeohydro
  otherURLs:
  - https://pypi.org/project/pygeohydro/
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{shawverQgridInteractiveGrid2017,\n  title = {Qgrid: {{An}} Interactive\
    \ Grid for Sorting, Filtering, and Editing {{DataFrames}} in {{Jupyter}} Notebooks},\n\
    \  author = {Shawver, Tim},\n  year = {2017},\n  url = {https://github.com/quantopian/qgrid},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: An interactive grid for sorting, filtering, and editing DataFrames
    in Jupyter notebooks.
  githubURL: https://github.com/quantopian/qgrid
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: qgrid
  otherURLs:
  - https://pypi.org/project/qgrid/0.3.2/#:~:text=Qgrid%20is%20an%20IPython%20widget,3.0).
  paperURL: ''
  releaseYear: 2017
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{aroussiQuantstatsPortfolioAnalytics2019,\n  title = {Quantstats:\
    \ {{Portfolio}} Analytics for Quants, Written in {{Python}}},\n  author = {Aroussi,\
    \ Ran},\n  year = {2019},\n  url = {https://github.com/ranaroussi/quantstats},\n\
    \  urldate = {2023-04-24},\n  copyright = {Apache-2.0}\n}\n"
  communication: ''
  description: Portfolio analytics for quants, written in Python.
  githubURL: https://github.com/ranaroussi/quantstats
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: quantstats
  otherURLs:
  - https://pypi.org/project/QuantStats/
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{venkatachalapathiQuickEDASimpleEasytouse2020,\n  title = {Quick-{{EDA}}:\
    \ {{Simple}} \\& {{Easy-to-use}} Python Modules to Perform {{Quick Exploratory\
    \ Data Analysis}} for Any Structured Dataset},\n  author = {Venkatachalapathi,\
    \ Sidheswar},\n  year = {2020},\n  url = {https://github.com/sid-the-coder/QuickDA},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT}\n}\n"
  communication: ''
  description: Simple & Easy-to-use python modules to perform Quick Exploratory Data
    Analysis for any structured dataset!
  githubURL: https://github.com/sid-the-coder/QuickDA
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: quickda
  otherURLs:
  - https://pypi.org/project/quickda/
  - https://medium.com/analytics-vidhya/quickda-low-code-python-library-for-quick-exploratory-data-analysis-b4b1c3af369d
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{microsoftResponsibleAIToolbox2020,\n  title = {Responsible {{AI Toolbox}}},\n\
    \  author = {Microsoft},\n  year = {2020},\n  url = {https://github.com/microsoft/responsible-ai-toolbox},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT},\n  howpublished = {Microsoft}\n\
    }\n"
  communication: ''
  description: Responsible AI Toolbox is a suite of tools providing model and data
    exploration and assessment user interfaces and libraries that enable a better
    understanding of AI systems. These interfaces and libraries empower developers
    and stakeholders of AI systems to develop and monitor AI more responsibly, and
    take better data-driven actions.
  githubURL: https://github.com/microsoft/responsible-ai-toolbox
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: raiwidgets
  otherURLs:
  - https://pypi.org/project/raiwidgets/
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{bertrandSweetVizIndepthEDA2020,\n  title = {{{SweetViz}}: {{In-depth\
    \ EDA}} in Two Lines of Code},\n  author = {Bertrand, Francois},\n  year = {2020},\n\
    \  url = {https://github.com/fbdesignpro/sweetviz},\n  urldate = {2023-04-24},\n\
    \  copyright = {MIT}\n}\n"
  communication: ''
  description: Visualize and compare datasets, target values and associations, with
    one line of code.
  githubURL: https://github.com/fbdesignpro/sweetviz
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: sweetviz
  otherURLs:
  - https://pypi.org/project/sweetviz/
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{dawson-haggertyetal.Trimesh2019,\n  title = {Trimesh},\n  author\
    \ = {{Dawson-Haggerty et al.}},\n  year = {2019},\n  url = {https://github.com/mikedh/trimesh}\n\
    }\n"
  communication: ''
  description: Python library for loading and using triangular meshes.
  githubURL: https://github.com/mikedh/trimesh
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: trimesh
  otherURLs:
  - https://pypi.org/project/trimesh/
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{haasGravisInteractiveGraph2021,\n  title = {Gravis: {{Interactive}}\
    \ Graph Visualizations with {{Python}} and {{HTML}}/{{CSS}}/{{JS}}},\n  author\
    \ = {Haas, Robert},\n  year = {2021},\n  url = {https://github.com/robert-haas/gravis},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Interactive graph visualizations with Python and HTML/CSS/JS.
  githubURL: https://github.com/robert-haas/gravis
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: gravis
  otherURLs:
  - https://robert-haas.github.io/gravis-docs/
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@inproceedings{lundbergUnifiedApproachInterpreting2017,\n  title = {A Unified\
    \ Approach to Interpreting Model Predictions},\n  booktitle = {Proceedings of\
    \ the 31st International Conference on Neural Information Processing Systems},\n\
    \  author = {Lundberg, Scott M. and Lee, Su-In},\n  year = {2017},\n  series =\
    \ {{{NIPS}}'17},\n  doi = {10.48550/arXiv.1705.07874}\n}\n"
  communication: ''
  description: A game theoretic approach to explain the output of any machine learning
    model.
  githubURL: https://github.com/slundberg/shap
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: shap
  otherURLs:
  - https://shap.readthedocs.io/en/latest/
  paperURL: ''
  releaseYear: 2017
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{aaltogisSpatialDataScience2020,\n  title = {Spatial {{Data Science}}\
    \ for {{Sustainable Development}}},\n  author = {AaltoGIS},\n  year = {2020},\n\
    \  url = {https://github.com/AaltoGIS/Sustainability-GIS},\n  urldate = {2023-04-24},\n\
    \  howpublished = {AaltoGIS}\n}\n"
  communication: ''
  description: '"Spatial Data Science for Sustainable Development" course at the Dept.
    Built Environment, Aalto University.'
  githubURL: https://github.com/AaltoGIS/Sustainability-GIS
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: spatialtis
  otherURLs:
  - https://sustainability-gis.readthedocs.io/en/latest/lessons/L1/intro-to-python-geostack.html
  paperURL: ''
  releaseYear: 2020
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{ToyplotInteractivePlotting2022,\n  title = {Toyplot: {{Interactive}}\
    \ Plotting for {{Python}}.},\n  year = {2022},\n  url = {https://github.com/sandialabs/toyplot},\n\
    \  urldate = {2023-04-24},\n  howpublished = {Sandia National Laboratories}\n\
    }\n"
  communication: ''
  description: Interactive plotting for Python.
  githubURL: https://github.com/sandialabs/toyplot
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: toyplot
  otherURLs:
  - https://toyplot.readthedocs.io/en/stable/
  - https://toyplot.readthedocs.io/en/stable/tutorial.html#Animation
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{weights&biasesWeightsBiasesTool2021,\n  title = {Weights \\& {{Biases}}:\
    \ {{A}} Tool for Visualizing and Tracking Your Machine Learning Experiments},\n\
    \  author = {Weights \\& Biases},\n  year = {2021},\n  url = {https://github.com/wandb/wandb},\n\
    \  urldate = {2023-04-24},\n  copyright = {MIT},\n  howpublished = {Weights \\\
    & Biases}\n}\n"
  communication: ''
  description: A tool for visualizing and tracking your machine learning experiments.
  githubURL: https://github.com/wandb/wandb
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: wandb
  otherURLs:
  - https://wandb.ai/site
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{nengoNengoPythonLibrary2019,\n  title = {Nengo: {{A Python}} Library\
    \ for Creating and Simulating Large-Scale Brain Models},\n  author = {Nengo},\n\
    \  year = {2019},\n  url = {https://github.com/nengo/nengo},\n  urldate = {2023-04-24},\n\
    \  howpublished = {Nengo}\n}\n"
  communication: ''
  description: A Python library for creating and simulating large-scale brain models.
  githubURL: https://github.com/nengo/nengo
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: nengo
  otherURLs:
  - https://www.nengo.ai/
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{hacklPathpyOpenSourcePython2019,\n  title = {Pathpy: {{An OpenSource}}\
    \ Python Package for the Analysis of Time Series Data on Networks Using Higher-Order\
    \ and Multi-Order Graphical Models.},\n  author = {Hackl, J{\\\"u}rgen},\n  year\
    \ = {2019},\n  url = {https://github.com/pathpy/pathpy},\n  urldate = {2023-04-24}\n\
    }\n"
  communication: ''
  description: An OpenSource python package for the analysis of time series data on
    networks using higher-order and multi-order graphical models.
  githubURL: https://github.com/pathpy/pathpy
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: pathpy
  otherURLs:
  - https://www.pathpy.net/
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{vizzuIpyvizzuBuildAnimated2022,\n  title = {Ipyvizzu: {{Build}} Animated\
    \ Charts in {{Jupyter Notebook}} and Similar Environments with a Simple {{Python}}\
    \ Syntax},\n  author = {Vizzu},\n  year = {2022},\n  url = {https://github.com/vizzuhq/ipyvizzu},\n\
    \  urldate = {2023-04-24},\n  copyright = {Apache-2.0},\n  howpublished = {Vizzu}\n\
    }\n"
  communication: ''
  description: Build animated charts in Jupyter Notebook and similar environments
    with a simple Python syntax.
  githubURL: https://github.com/vizzuhq/ipyvizzu
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: ipyvizzu
  otherURLs: []
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{quantstackIpytreeTreeWidget2022,\n  title = {Ipytree: {{A Tree Widget}}\
    \ Using {{Jupyter-widgets}} Protocol and {{jsTree}}},\n  author = {QuantStack},\n\
    \  year = {2022},\n  url = {https://github.com/QuantStack/ipytree},\n  urldate\
    \ = {2023-04-24},\n  copyright = {MIT},\n  howpublished = {QuantStack}\n}\n"
  communication: ''
  description: A Tree Widget using Jupyter-widgets protocol and jsTree.
  githubURL: https://github.com/QuantStack/ipytree/
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: ipytree
  otherURLs: []
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{evidentlyaiEvidentlyEvaluateMonitor2022,\n  title = {Evidently: {{Evaluate}}\
    \ and Monitor {{ML}} Models from Validation to Production},\n  author = {Evidently\
    \ AI},\n  year = {2022},\n  url = {https://github.com/evidentlyai/evidently},\n\
    \  urldate = {2023-04-24},\n  copyright = {Apache-2.0},\n  howpublished = {Evidently\
    \ AI}\n}\n"
  communication: ''
  description: Evaluate and monitor ML models from validation to production.
  githubURL: https://github.com/evidentlyai/evidently
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: evidently
  otherURLs: []
  paperURL: ''
  releaseYear: 2022
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{quantstackIpysheetJupyterHandsontable2017,\n  title = {Ipysheet:\
    \ {{Jupyter}} Handsontable Integration},\n  author = {QuantStack},\n  year = {2017},\n\
    \  url = {https://github.com/QuantStack/ipysheet},\n  urldate = {2023-04-24},\n\
    \  copyright = {MIT},\n  howpublished = {QuantStack}\n}\n"
  communication: ''
  description: Jupyter handsontable integration.
  githubURL: https://github.com/QuantStack/ipysheet/
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: ipysheet
  otherURLs: []
  paperURL: ''
  releaseYear: 2017
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{bloombergIpydatagridFastDatagrid2019,\n  title = {Ipydatagrid: {{Fast\
    \ Datagrid}} Widget for the {{Jupyter Notebook}} and {{JupyterLab}}},\n  author\
    \ = {Bloomberg},\n  year = {2019},\n  url = {https://github.com/bloomberg/ipydatagrid},\n\
    \  urldate = {2023-04-24},\n  copyright = {BSD-3-Clause},\n  howpublished = {Bloomberg}\n\
    }\n"
  communication: ''
  description: Fast Datagrid widget for the Jupyter Notebook and JupyterLab.
  githubURL: https://github.com/bloomberg/ipydatagrid
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: ipydatagrid
  otherURLs: []
  paperURL: ''
  releaseYear: 2019
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{nvidiaNVDashboardJupyterLabExtension2021,\n  title = {{{NVDashboard}}:\
    \ {{A JupyterLab}} Extension for Displaying Dashboards of {{GPU}} Usage},\n  author\
    \ = {NVIDIA},\n  year = {2021},\n  url = {https://github.com/rapidsai/jupyterlab-nvdashboard},\n\
    \  urldate = {2023-04-21},\n  copyright = {BSD-3-Clause},\n  howpublished = {RAPIDS}\n\
    }\n"
  communication: ''
  description: A JupyterLab extension for displaying dashboards of GPU usage.
  githubURL: https://github.com/rapidsai/jupyterlab-nvdashboard
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: nvdashboard
  otherURLs: []
  paperURL: ''
  releaseYear: 2021
  sourceType: package
  supportedNotebooks: []
  user: ''

- bibtex: "@misc{loganNbtutorVisualizePython2023,\n  title = {Nbtutor: {{Visualize\
    \ Python}} Code Execution (Line-by-Line) in {{Jupyter Notebook}} Cells},\n  author\
    \ = {Logan},\n  year = {2023},\n  url = {https://github.com/lgpage/nbtutor},\n\
    \  urldate = {2023-04-24}\n}\n"
  communication: ''
  description: Visualize Python code execution (line-by-line) in Jupyter Notebook
    cells.
  githubURL: https://github.com/lgpage/nbtutor
  implementation: ''
  layouts: []
  materials: []
  modularity: ''
  name: nbtutor
  otherURLs: []
  paperURL: ''
  releaseYear: 2023
  sourceType: package
  supportedNotebooks: []
  user: ''

