{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import io\n",
    "import yaml\n",
    "\n",
    "from glob import glob\n",
    "from os.path import exists, join, basename\n",
    "from bs4 import BeautifulSoup\n",
    "from shutil import copyfileobj, copyfile\n",
    "from PIL import Image\n",
    "from time import sleep\n",
    "from requests_ip_rotator import ApiGateway, EXTRA_REGIONS, ALL_REGIONS\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Interesting.html', 'r') as fp:\n",
    "    content = fp.read()\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "table = soup.find('table')\n",
    "rows = table.find_all('tr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API gateways in 10 regions.\n",
      "Using 10 endpoints with name 'https://lh3.googleusercontent.com - IP Rotate API' (10 new).\n"
     ]
    }
   ],
   "source": [
    "gateway = ApiGateway(\"https://lh3.googleusercontent.com\")\n",
    "gateway.start()\n",
    "\n",
    "session = requests.Session()\n",
    "session.mount(\"https://lh3.googleusercontent.com\", gateway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting gateways for site 'https://lh3.googleusercontent.com'.\n",
      "Deleted 10 endpoints with for site 'https://lh3.googleusercontent.com'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gscpqvepih',\n",
       " 'qjtiexfvmg',\n",
       " '15c4spf8qa',\n",
       " 'np9jcvzv66',\n",
       " 'bz71fik6fk',\n",
       " '00k9n7p6qg',\n",
       " 'rsheulakgl',\n",
       " 'dsntxv5jae',\n",
       " 'g5bad9h7d7',\n",
       " 'ndevqvh507']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gateway.shutdown() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [02:01,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "existing_files = set([basename(f).replace('.webp', '') for f in glob('./thumbnails/*.webp')])\n",
    "\n",
    "for i, row in tqdm(enumerate(rows)):\n",
    "\n",
    "    name = row.find('td', class_='s2')\n",
    "    if name is None:\n",
    "        continue\n",
    "    \n",
    "    name = name.text.lower().replace(' ', '-')\n",
    "    name = name.split('.')[0]\n",
    "    \n",
    "    if name in existing_files:\n",
    "        continue\n",
    "    \n",
    "    # Remove the size query from image_src\n",
    "    image_src = row.find('td', class_='s6').find('img').get('src')\n",
    "    image_src = re.sub(r'^(.*)=w\\d+-h\\d+$', r'\\1', image_src)\n",
    "    \n",
    "    # Save the image as webp\n",
    "    response = session.get(image_src, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        image = Image.open(io.BytesIO(response.content))\n",
    "        image_file_path = f'./thumbnails/{name}.webp'\n",
    "        image.save(image_file_path, lossless=False, quality=80)\n",
    "        sleep(0.5)\n",
    "    else:\n",
    "        print(response.status_code, response, name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Papers.html', 'r') as fp:\n",
    "    content = fp.read()\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "table = soup.find('table')\n",
    "rows = table.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API gateways in 10 regions.\n",
      "Using 10 endpoints with name 'https://lh3.googleusercontent.com - IP Rotate API' (10 new).\n"
     ]
    }
   ],
   "source": [
    "gateway = ApiGateway(\"https://lh3.googleusercontent.com\")\n",
    "gateway.start()\n",
    "\n",
    "session = requests.Session()\n",
    "session.mount(\"https://lh3.googleusercontent.com\", gateway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:48<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "existing_files = set([basename(f).replace('.webp', '') for f in glob('./thumbnails/*.webp')])\n",
    "\n",
    "for i, row in tqdm(enumerate(rows), total=len(rows)):\n",
    "    name = row.find('td', class_='s3')\n",
    "    if name is None:\n",
    "        continue\n",
    "    \n",
    "    name = name.text.lower().replace(' ', '-')\n",
    "    name = name.split('.')[0]\n",
    "    \n",
    "    if name in existing_files:\n",
    "        continue\n",
    "    \n",
    "    # Remove the size query from image_src\n",
    "    image = row.find('td', class_='s7')\n",
    "    \n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    image_src = image.find('img').get('src')\n",
    "    image_src = re.sub(r'^(.*)=w\\d+-h\\d+$', r'\\1', image_src)\n",
    "    \n",
    "    # Save the image as webp\n",
    "    response = session.get(image_src, stream=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        image = Image.open(io.BytesIO(response.content))\n",
    "        image_file_path = f'./thumbnails/{name}.webp'\n",
    "        image.save(image_file_path, lossless=False, quality=80)\n",
    "        sleep(0.5)\n",
    "    else:\n",
    "        print(response.status_code, response, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting gateways for site 'https://lh3.googleusercontent.com'.\n",
      "Deleted 10 endpoints with for site 'https://lh3.googleusercontent.com'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['znn1mqmwa5',\n",
       " '2bxtdqbpgl',\n",
       " '74belsv5cf',\n",
       " '8p2sdd9uxc',\n",
       " '8g9644cxgh',\n",
       " 'itjp6b1urd',\n",
       " 'ihopk6donc',\n",
       " 'koqcgyqr3h',\n",
       " 'hiv6m06fi5',\n",
       " 'ls5zppy2he']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gateway.shutdown() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse BibTex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./notebook-va.bib', 'r') as fp:\n",
    "    lines = [l for l in fp.readlines()]\n",
    "\n",
    "bibtex_entries = []\n",
    "cur_entry = ''\n",
    "for line in lines:\n",
    "    if line == '\\n':\n",
    "       bibtex_entries.append(cur_entry)\n",
    "       cur_entry = ''\n",
    "    \n",
    "    else:\n",
    "        cur_entry += line\n",
    "\n",
    "bibtex_entries.append(cur_entry)\n",
    "\n",
    "# Create a dictionary that maps bibtex key to the entry\n",
    "bibtex_dict = {}\n",
    "\n",
    "for i, entry in enumerate(bibtex_entries):\n",
    "    first_line = entry.split('\\n')[0]\n",
    "    key = re.sub(r'^@.+{(.+),.*$', r'\\1', first_line)\n",
    "    \n",
    "    # Also parse the year\n",
    "    year = int(re.sub(r'^.*(\\d{4})[a-z]?$', r'\\1', key))\n",
    "    \n",
    "    bibtex_dict[key] = {\n",
    "        'bibtex': entry,\n",
    "        'year': year\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Meta Data (Packages + Papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Interesting.html', 'r') as fp:\n",
    "    content = fp.read()\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "package_table = soup.find('table')\n",
    "package_rows = package_table.find_all('tr')\n",
    "\n",
    "with open('./Papers.html', 'r') as fp:\n",
    "    content = fp.read()\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "paper_table = soup.find('table')\n",
    "paper_rows = paper_table.find_all('tr')\n",
    "\n",
    "def create_new_entry():\n",
    "    return {\n",
    "        'name': '',\n",
    "        'githubURL': '',\n",
    "        'paperURL': '',\n",
    "        'otherURLs': [],\n",
    "        'description': '',\n",
    "        'bibtex': '',\n",
    "        'sourceType': '',\n",
    "        'releaseYear': 0,\n",
    "        'communication': '',\n",
    "        'materials': [],\n",
    "        'layouts': [],\n",
    "        'supportedNotebooks': [],\n",
    "        'modularity': '',\n",
    "        'user': '',\n",
    "        'implementation': '',\n",
    "        'modularity': ''\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "\n",
    "# Parse papers first\n",
    "for i, row in tqdm(enumerate(paper_rows), disable=True):\n",
    "\n",
    "    columns = row.find_all('td')\n",
    "    if columns is None or len(columns) == 0:\n",
    "        continue\n",
    "    \n",
    "    entry = create_new_entry()\n",
    "    entry['sourceType'] = 'paper'\n",
    "    \n",
    "    # Get the package name\n",
    "    name = columns[0]\n",
    "    name = name.text.lower().replace(' ', '-')\n",
    "    name = name.split('.')[0]\n",
    "    entry['name'] = name\n",
    "    \n",
    "    if name is None or name == '' or name == 'name':\n",
    "        continue\n",
    "    \n",
    "    # Get the paper url\n",
    "    tags = columns[1]\n",
    "    tags = tags.find_all('a', recursive=True)\n",
    "    urls = [tag.get('href') for tag in tags]\n",
    "    \n",
    "    for url in urls:\n",
    "        if entry['paperURL'] == '':\n",
    "            entry['paperURL'] = url\n",
    "            \n",
    "    # Get the description\n",
    "    description = columns[3].text\n",
    "    entry['description'] = description\n",
    "    \n",
    "    # Get the github url\n",
    "    tag = columns[4]\n",
    "    tag = tag.find('a', recursive=True)\n",
    "    if tag is not None:\n",
    "        entry['githubURL'] = tag.get('href')\n",
    "    \n",
    "    # # Get the bibtex\n",
    "    bibtex_key = columns[2].text\n",
    "    \n",
    "    try:\n",
    "        entry['bibtex'] = bibtex_dict[bibtex_key]['bibtex']\n",
    "        entry['releaseYear'] = bibtex_dict[bibtex_key]['year']\n",
    "    \n",
    "    except:\n",
    "        print(bibtex_key)\n",
    "            \n",
    "    entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate:  interpretml\n",
      "Duplicate:  visual-auditor\n",
      "Duplicate:  pipelineprofiler\n",
      "Duplicate:  vizseq\n",
      "Duplicate:  what-if-tool\n"
     ]
    }
   ],
   "source": [
    "# Prase packages\n",
    "existing_names = set([entry['name'] for entry in entries])\n",
    "\n",
    "for i, row in tqdm(enumerate(package_rows), disable=True):\n",
    "\n",
    "    columns = row.find_all('td')\n",
    "    if columns is None or len(columns) == 0:\n",
    "        continue\n",
    "    \n",
    "    entry = create_new_entry()\n",
    "    entry['sourceType'] = 'package'\n",
    "    \n",
    "    # Get the package name\n",
    "    name = columns[0]\n",
    "    name = name.text.lower().replace(' ', '-')\n",
    "    name = name.split('.')[0]\n",
    "    \n",
    "    # skip duplicates from papers\n",
    "    if name in existing_names:\n",
    "        print('Duplicate: ', name)\n",
    "        continue\n",
    "\n",
    "    entry['name'] = name\n",
    "    \n",
    "    if name is None or name == '' or name == 'module':\n",
    "        continue\n",
    "    \n",
    "    # Get the package urls\n",
    "    tags = columns[2]\n",
    "    tags = tags.find_all('a', recursive=True)\n",
    "    urls = [tag.get('href') for tag in tags]\n",
    "    \n",
    "    for url in urls:\n",
    "        if 'github.com' in url:\n",
    "            if entry['githubURL'] == '':\n",
    "                entry['githubURL'] = url\n",
    "            else:\n",
    "                entry['otherURLs'].append(url)    \n",
    "        else:\n",
    "            entry['otherURLs'].append(url)\n",
    "            \n",
    "    # Get the description\n",
    "    description = columns[3].text\n",
    "    entry['description'] = description\n",
    "    \n",
    "    # Get the bibtex\n",
    "    bibtex_key = columns[4].text\n",
    "    \n",
    "    try:\n",
    "        entry['bibtex'] = bibtex_dict[bibtex_key]['bibtex']\n",
    "        entry['releaseYear'] = bibtex_dict[bibtex_key]['year']\n",
    "    \n",
    "    except:\n",
    "        print(bibtex_key)\n",
    "            \n",
    "    entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./resources/supernova.yaml', 'w+') as fp:\n",
    "    for entry in entries:\n",
    "        fp.write(yaml.dump([entry]))\n",
    "        fp.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
